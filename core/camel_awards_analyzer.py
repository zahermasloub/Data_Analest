# -*- coding: utf-8 -*-
"""
ğŸ† Ù…Ø­Ù„Ù„ Ø¬ÙˆØ§Ø¦Ø² Ø³Ø¨Ø§Ù‚Ø§Øª Ø§Ù„Ù‡Ø¬Ù†
Camel Race Awards Analyzer
================================
Ù†Ø¸Ø§Ù… Ù…ØªÙ‚Ø¯Ù… Ù„ØªØ­Ù„ÙŠÙ„ ÙˆÙ…Ø·Ø§Ø¨Ù‚Ø© Ø¬ÙˆØ§Ø¦Ø² Ø³Ø¨Ø§Ù‚Ø§Øª Ø§Ù„Ù‡Ø¬Ù† Ù…Ø¹ ÙƒØ´ÙˆÙØ§Øª Ø§Ù„Ø¨Ù†Ùƒ
ÙˆØ§ÙƒØªØ´Ø§Ù Ø§Ù„ØµØ±Ù Ø§Ù„Ù…ÙƒØ±Ø± ÙˆØ§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© v2.0:
- Ù…Ø·Ø§Ø¨Ù‚Ø© 3 Ø·Ø¨Ù‚Ø§Øª: Exact â†’ Fuzzy â†’ Record Linkage
- ØªØ³Ø¬ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù…Ø¹ Audit Trail
- Ø£Ø¯Ø§Ø¡ Ù…Ø­Ø³Ù‘Ù† Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime, timedelta
from pathlib import Path
import re
from rapidfuzz import fuzz
import warnings
import time

warnings.filterwarnings('ignore')

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
try:
    from core.advanced_matcher import AdvancedMatcher
    ADVANCED_MATCHER_AVAILABLE = True
except ImportError:
    ADVANCED_MATCHER_AVAILABLE = False
    warnings.warn("âš ï¸ Advanced Matcher ØºÙŠØ± Ù…ØªÙˆÙØ± - Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©")

try:
    from core.audit_logger import AuditLogger
    AUDIT_LOGGER_AVAILABLE = True
except ImportError:
    AUDIT_LOGGER_AVAILABLE = False
    warnings.warn("âš ï¸ Audit Logger ØºÙŠØ± Ù…ØªÙˆÙØ± - Ù„Ù† ÙŠØªÙ… Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„Ø§Øª")

try:
    from core.performance_optimizer import PerformanceOptimizer, recommend_optimizer_settings
    PERFORMANCE_OPTIMIZER_AVAILABLE = True
except ImportError:
    PERFORMANCE_OPTIMIZER_AVAILABLE = False
    warnings.warn("âš ï¸ Performance Optimizer ØºÙŠØ± Ù…ØªÙˆÙØ± - Ø§Ø³ØªØ®Ø¯Ø§Ù… pandas Ø§Ù„Ø¹Ø§Ø¯ÙŠ")


class CamelAwardsAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø¬ÙˆØ§Ø¦Ø² Ø³Ø¨Ø§Ù‚Ø§Øª Ø§Ù„Ù‡Ø¬Ù† - Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…ØªÙ‚Ø¯Ù… v2.0"""
    
    def __init__(self, use_advanced_features: bool = True):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ù„Ù„
        
        Args:
            use_advanced_features: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© (Ù…Ø·Ø§Ø¨Ù‚Ø© 3 Ø·Ø¨Ù‚Ø§ØªØŒ ØªØ³Ø¬ÙŠÙ„ØŒ Ø£Ø¯Ø§Ø¡ Ù…Ø­Ø³Ù‘Ù†)
        """
        # Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        self.awards_data = None
        self.bank_data = None
        self.merged_results = None
        self.statistics = {}
        
        # Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        self.use_advanced_features = use_advanced_features
        self.matcher = None
        self.logger = None
        self.optimizer = None
        self.current_run_id = None
        
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        if use_advanced_features:
            if ADVANCED_MATCHER_AVAILABLE:
                self.matcher = AdvancedMatcher(fuzzy_threshold=90)
                print("âœ… Advanced Matcher Ù…ÙØ¹Ù‘Ù„")
            
            if AUDIT_LOGGER_AVAILABLE:
                self.logger = AuditLogger(log_dir="outputs/audit_logs")
                print("âœ… Audit Logger Ù…ÙØ¹Ù‘Ù„")
            
            # Performance Optimizer ÙŠØªÙ… ØªÙ‡ÙŠØ¦ØªÙ‡ Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©
            if PERFORMANCE_OPTIMIZER_AVAILABLE:
                print("âœ… Performance Optimizer Ù…ØªØ§Ø­")
        
    def normalize_text(self, text: str) -> str:
        """
        ØªØ·Ø¨ÙŠØ¹ ÙˆØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ
        
        Args:
            text: Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ·Ø¨ÙŠØ¹Ù‡
            
        Returns:
            Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø·Ø¨Ù‘Ø¹
        """
        if pd.isna(text) or not isinstance(text, str):
            return ""

        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø¥Ù„Ù‰ Ù†Øµ ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙˆØ§ØµÙ„ Ø§Ù„Ø³ÙÙ„ÙŠØ© ÙƒÙ…Ø³Ø§ÙØ§Øª
        text = str(text).replace('_', ' ')
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
        text = re.sub(r'\s+', ' ', text).strip()

        # ØªÙˆØ­ÙŠØ¯ Unicode (ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)
        text = text.replace('Ø£', 'Ø§').replace('Ø¥', 'Ø§').replace('Ø¢', 'Ø§')
        text = text.replace('Ø©', 'Ù‡')
        text = text.replace('Ù‰', 'ÙŠ')
        
        # ØªØ­ÙˆÙŠÙ„ Ù„Ø£Ø­Ø±Ù ØµØºÙŠØ±Ø©
        text = text.lower()
        
        return text
    
    def normalize_column_names(self, df: pd.DataFrame, context: str = "generic") -> pd.DataFrame:
        """
        ØªÙˆØ­ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        
        Args:
            df: DataFrame Ø§Ù„Ù…Ø±Ø§Ø¯ ØªÙˆØ­ÙŠØ¯ Ø£Ø¹Ù…Ø¯ØªÙ‡
            context: Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (awards / bank / generic)
            
        Returns:
            DataFrame Ø¨Ø£Ø¹Ù…Ø¯Ø© Ù…ÙˆØ­Ø¯Ø©
        """
        df_copy = df.copy()
        df_copy.columns = [self.normalize_text(col) for col in df_copy.columns]

        def canonical(label: str) -> str:
            return self.normalize_text(label).replace(' ', '')

        # Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        base_groups = {
            'Season': ['season', 'Ø§Ù„Ù…ÙˆØ³Ù…', 'Ù…ÙˆØ³Ù…'],
            'Race': ['race', 'Ø§Ù„Ø³Ø¨Ø§Ù‚', 'Ø³Ø¨Ø§Ù‚', 'race name', 'Ø§Ø³Ù… Ø§Ù„Ø³Ø¨Ø§Ù‚'],
            'AwardAmount': ['award amount', 'awardamount', 'amount', 'Ø§Ù„Ù…Ø¨Ù„Øº', 'Ù…Ø¨Ù„Øº', 'Ø§Ù„Ù‚ÙŠÙ…Ø©', 'Ø§Ù„Ø¬Ø§Ø¦Ø²Ø©', 'value'],
            'EntryDate': ['entrydate', 'entry date', 'date', 'Ø§Ù„ØªØ§Ø±ÙŠØ®', 'ØªØ§Ø±ÙŠØ®', 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„', 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø³Ø¨Ø§Ù‚']
        }

        awards_groups = {
            'OwnerName': ['ownername', 'Ø§Ø³Ù… Ø§Ù„Ù…Ø§Ù„Ùƒ', 'Ø§Ù„Ù…Ø§Ù„Ùƒ', 'Ø§Ù„Ø§Ø³Ù…', 'owner name']
        }

        bank_groups = {
            'BankName': ['bankname', 'Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙÙŠØ¯', 'Ø§Ù„Ù…Ø³ØªÙÙŠØ¯', 'beneficiary', 'beneficiary name', 'name', 'ownername'],
            'BankAmount': ['bankamount', 'Ù…Ø¨Ù„Øº Ø§Ù„ØªØ­ÙˆÙŠÙ„', 'payment amount', 'amount', 'debit', 'credit'],
            'BankDate': ['bankdate', 'ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­ÙˆÙŠÙ„', 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯ÙØ¹', 'payment date', 'transaction date'],
            'BankReference': ['bankreference', 'reference', 'Ø§Ù„Ù…Ø±Ø¬Ø¹', 'Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø¬Ø¹', 'Ø±Ù‚Ù… Ø§Ù„Ø¹Ù…Ù„ÙŠØ©', 'request reference', 'bank ref', 'award ref', 'award ref 10 digits']
        }

        def build_mapping(groups: Dict[str, List[str]]) -> Dict[str, str]:
            mapping: Dict[str, str] = {}
            for target, aliases in groups.items():
                for alias in aliases:
                    mapping[canonical(alias)] = target
            return mapping

        mapping = build_mapping(base_groups)

        if context == 'awards':
            mapping.update(build_mapping(awards_groups))
        elif context == 'bank':
            mapping.update(build_mapping(bank_groups))
        else:
            mapping.update(build_mapping(awards_groups))
            mapping.update(build_mapping(bank_groups))

        rename_map: Dict[str, str] = {}
        for col in df_copy.columns:
            key = canonical(col)
            if key in mapping:
                rename_map[col] = mapping[key]

        df_copy.rename(columns=rename_map, inplace=True)

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¨Ù†Ùƒ: Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ³Ù…ÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø­Ø±Ø¬Ø©
        if context == 'bank':
            if 'BankName' not in df_copy.columns and 'OwnerName' in df_copy.columns:
                df_copy.rename(columns={'OwnerName': 'BankName'}, inplace=True)

            if 'BankDate' not in df_copy.columns:
                for fallback in ['transaction date', 'value date']:
                    if fallback in df_copy.columns:
                        df_copy.rename(columns={fallback: 'BankDate'}, inplace=True)
                        break

        return df_copy
    
    def load_awards_files(self, files: List[Any]) -> pd.DataFrame:
        """
        ØªØ­Ù…ÙŠÙ„ ÙˆØ¯Ù…Ø¬ Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬ÙˆØ§Ø¦Ø²
        
        Args:
            files: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ù…Ù„ÙØ§Øª Excel Ù„Ù„Ø¬ÙˆØ§Ø¦Ø²
            
        Returns:
            DataFrame Ù…ÙˆØ­Ø¯ Ù„Ù„Ø¬ÙˆØ§Ø¦Ø²
        """
        all_data = []
        
        for file in files:
            try:
                # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
                if hasattr(file, 'name'):
                    if file.name.endswith('.csv'):
                        df = pd.read_csv(file)
                    else:
                        df = pd.read_excel(file)
                else:
                    df = pd.read_excel(file)
                
                # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
                df = self.normalize_column_names(df, context="awards")
                
                all_data.append(df)
                
            except Exception as e:
                print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {str(e)}")
                continue
        
        if not all_data:
            raise ValueError("Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£ÙŠ Ù…Ù„ÙØ§Øª Ø¨Ù†Ø¬Ø§Ø­")
        
        # Ø¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
        self.awards_data = pd.concat(all_data, ignore_index=True)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù…Ø·Ø¨Ù‘Ø¹
        if 'OwnerName' in self.awards_data.columns:
            self.awards_data['OwnerName_norm'] = self.awards_data['OwnerName'].apply(self.normalize_text)
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
        if 'EntryDate' in self.awards_data.columns:
            self.awards_data['EntryDate'] = pd.to_datetime(
                self.awards_data['EntryDate'], 
                errors='coerce',
                dayfirst=True
            )
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ù„Øº Ù„Ø£Ø±Ù‚Ø§Ù…
        if 'AwardAmount' in self.awards_data.columns:
            self.awards_data['AwardAmount'] = pd.to_numeric(
                self.awards_data['AwardAmount'], 
                errors='coerce'
            )
        
        return self.awards_data
    
    def load_bank_statement(self, file: Any) -> pd.DataFrame:
        """
        ØªØ­Ù…ÙŠÙ„ ÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ
        
        Args:
            file: Ù…Ù„Ù Excel Ù„ÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ
            
        Returns:
            DataFrame Ù„ÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ
        """
        try:
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
            if hasattr(file, 'name'):
                if file.name.endswith('.csv'):
                    df = pd.read_csv(file)
                else:
                    # Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© Ù…Ù† ØµÙÙˆÙ Ù…Ø®ØªÙ„ÙØ© (ÙÙŠ Ø­Ø§Ù„ ÙƒØ§Ù†Øª headers ÙÙŠ ØµÙ ØºÙŠØ± Ø§Ù„Ø£ÙˆÙ„)
                    df = pd.read_excel(file, header=None)
                    
                    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØµÙ Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ headers
                    header_row = 0
                    for i in range(min(10, len(df))):
                        row_values = df.iloc[i].astype(str).str.lower()
                        if any('name' in str(v) or 'Ø§Ø³Ù…' in str(v) or 'amount' in str(v) or 'Ù…Ø¨Ù„Øº' in str(v) for v in row_values):
                            header_row = i
                            break
                    
                    # Ø¥Ø¹Ø§Ø¯Ø© Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ù…Ø¹ Ø§Ù„Ù€ header Ø§Ù„ØµØ­ÙŠØ­
                    if header_row > 0:
                        df = pd.read_excel(file, header=header_row)
                    else:
                        df = pd.read_excel(file)
            else:
                df = pd.read_excel(file)
            
            # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            df = self.normalize_column_names(df, context="bank")

            # Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø¨Ù„Øº Ø§Ù„Ø¨Ù†ÙƒÙŠ Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø¥ÙŠØ¬Ø§Ø¯Ù‡ Ù…Ø¨Ø§Ø´Ø±Ø©
            if 'BankAmount' not in df.columns:
                debit_col = None
                credit_col = None
                for col in df.columns:
                    if col.lower() == 'debit':
                        debit_col = col
                    elif col.lower() == 'credit':
                        credit_col = col
                if debit_col and credit_col:
                    df['BankAmount'] = df[debit_col].fillna(0) - df[credit_col].fillna(0)
                elif debit_col:
                    df['BankAmount'] = df[debit_col]
                elif credit_col:
                    df['BankAmount'] = df[credit_col]

            # ØªØ¹ÙŠÙŠÙ† ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ù†Ùƒ Ù…Ù† Ø£Ø¹Ù…Ø¯Ø© Ø¨Ø¯ÙŠÙ„Ø© Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
            if 'BankDate' not in df.columns:
                for fallback in ['Transaction Date', 'Value Date']:
                    if fallback in df.columns:
                        df.rename(columns={fallback: 'BankDate'}, inplace=True)
                        break
            
            self.bank_data = df
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù…Ø·Ø¨Ù‘Ø¹
            if 'BankName' in self.bank_data.columns:
                self.bank_data['BankName_norm'] = self.bank_data['BankName'].apply(self.normalize_text)
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
            if 'BankDate' in self.bank_data.columns:
                self.bank_data['BankDate'] = pd.to_datetime(
                    self.bank_data['BankDate'], 
                    errors='coerce',
                    dayfirst=True
                )
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ù„Øº Ù„Ø£Ø±Ù‚Ø§Ù…
            if 'BankAmount' in self.bank_data.columns:
                self.bank_data['BankAmount'] = pd.to_numeric(
                    self.bank_data['BankAmount'], 
                    errors='coerce'
                )
            
            return self.bank_data
            
        except Exception as e:
            raise ValueError(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ ÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ: {str(e)}")
    
    def match_with_bank(
        self,
        time_window_days: int = 7,
        use_record_linkage: bool = False,
        files_info: Optional[Dict[str, List[str]]] = None
    ) -> pd.DataFrame:
        """
        Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬ÙˆØ§Ø¦Ø² Ù…Ø¹ ÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ (Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…ØªÙ‚Ø¯Ù… v2.0)
        
        Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©:
        - Ù…Ø·Ø§Ø¨Ù‚Ø© 3 Ø·Ø¨Ù‚Ø§Øª: Exact â†’ Fuzzy â†’ Record Linkage
        - ØªØ³Ø¬ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù…Ø¹ Audit Trail
        - Ø£Ø¯Ø§Ø¡ Ù…Ø­Ø³Ù‘Ù† Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
        
        Args:
            time_window_days: Ù†Ø§ÙØ°Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø²Ù…Ù†ÙŠ Ø¨Ø§Ù„Ø£ÙŠØ§Ù…
            use_record_linkage: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø·Ø§Ø¨Ù‚Ø© Record Linkage (Ù„Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„ØµØ¹Ø¨Ø©)
            files_info: Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù„ØªØ³Ø¬ÙŠÙ„ (dict Ù…Ø¹ Ù…ÙØ§ØªÙŠØ­ 'awards_files', 'bank_file')
            
        Returns:
            DataFrame Ø¨Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        """
        if self.awards_data is None or self.bank_data is None:
            raise ValueError("ÙŠØ¬Ø¨ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬ÙˆØ§Ø¦Ø² ÙˆÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ Ø£ÙˆÙ„Ø§Ù‹")
        
        print(f"\nğŸ” Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©...")
        print(f"   ğŸ“Š Ø¬ÙˆØ§Ø¦Ø²: {len(self.awards_data):,} Ø³Ø¬Ù„")
        print(f"   ğŸ¦ Ø¨Ù†Ùƒ: {len(self.bank_data):,} Ø³Ø¬Ù„")
        print(f"   â° Ù†Ø§ÙØ°Ø© Ø²Ù…Ù†ÙŠØ©: Â±{time_window_days} ÙŠÙˆÙ…")
        
        start_time = time.time()
        
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
            if self.use_advanced_features and self.matcher and ADVANCED_MATCHER_AVAILABLE:
                print(f"   âœ¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… Advanced Matcher (3 Ø·Ø¨Ù‚Ø§Øª)")
                
                # Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª
                matched_df, unmatched_df = self.matcher.match_all_layers(
                    awards_df=self.awards_data,
                    bank_df=self.bank_data,
                    time_window_days=time_window_days,
                    use_record_linkage=use_record_linkage
                )
                
                # Ø¥Ø¶Ø§ÙØ© Ø£Ø¹Ù…Ø¯Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„ØªÙˆØ§ÙÙ‚
                if len(matched_df) > 0:
                    matched_df['StatusFlag'] = 'âœ…'
                    matched_df['ReasonText'] = matched_df.apply(
                        lambda x: f"Ù…Ø·Ø§Ø¨Ù‚Ø© {x['MatchType']} Ø¨Ù†Ø³Ø¨Ø© {x['MatchScore']}%",
                        axis=1
                    )
                
                if len(unmatched_df) > 0:
                    unmatched_df['MatchType'] = 'No Match'
                    unmatched_df['MatchScore'] = 0
                    unmatched_df['BankDate'] = None
                    unmatched_df['BankReference'] = None
                    unmatched_df['StatusFlag'] = 'âš ï¸'
                    unmatched_df['ReasonText'] = 'Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø·Ø§Ø¨Ù‚Ø©'
                
                # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                self.merged_results = pd.concat([matched_df, unmatched_df], ignore_index=True)
                
            else:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù‚Ø¯ÙŠÙ…)
                print(f"   âš ï¸ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Exact + Fuzzy ÙÙ‚Ø·)")
                self.merged_results = self._basic_matching(time_window_days)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            execution_time = time.time() - start_time
            
            exact_matches = len(self.merged_results[self.merged_results['MatchType'] == 'Exact'])
            fuzzy_matches = len(self.merged_results[self.merged_results['MatchType'] == 'Fuzzy'])
            rl_matches = len(self.merged_results[self.merged_results['MatchType'] == 'RecordLinkage'])
            unmatched = len(self.merged_results[self.merged_results['MatchType'] == 'No Match'])
            
            self.statistics = {
                'total_awards': len(self.awards_data),
                'total_bank_records': len(self.bank_data),
                'exact_matches': exact_matches,
                'fuzzy_matches': fuzzy_matches,
                'rl_matches': rl_matches,
                'unmatched_awards': unmatched,
                'execution_time': execution_time,
                'time_window_days': time_window_days,
                'use_record_linkage': use_record_linkage
            }
            
            # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Audit Logger
            if self.use_advanced_features and self.logger and AUDIT_LOGGER_AVAILABLE:
                try:
                    # ØªØ­Ø¯ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª
                    if files_info:
                        awards_files = files_info.get('awards_files', ['unknown'])
                        bank_file = files_info.get('bank_file', 'unknown')
                    else:
                        awards_files = ['multiple_files']
                        bank_file = 'bank_statement.xlsx'
                    
                    self.current_run_id = self.logger.log_analysis_run(
                        awards_files=awards_files,
                        bank_file=bank_file,
                        statistics=self.statistics,
                        time_window_days=time_window_days,
                        fuzzy_threshold=90,
                        use_record_linkage=use_record_linkage,
                        execution_time=execution_time,
                        user_name="System",
                        status="Success"
                    )
                    
                    # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø§Øª
                    if len(self.merged_results[self.merged_results['MatchType'] != 'No Match']) > 0:
                        matches_only = self.merged_results[self.merged_results['MatchType'] != 'No Match']
                        self.logger.log_matches(self.current_run_id, matches_only)
                    
                    print(f"   ğŸ“ ØªÙ… Ø§Ù„ØªØ³Ø¬ÙŠÙ„: RunID={self.current_run_id[:8]}...")
                    
                except Exception as e:
                    print(f"   âš ï¸ ØªØ­Ø°ÙŠØ±: ÙØ´Ù„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ - {str(e)}")
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            print(f"\nâœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© ÙÙŠ {execution_time:.2f} Ø«Ø§Ù†ÙŠØ©")
            print(f"   âœ”ï¸ Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Ø­ØªÙ…ÙŠØ©: {exact_matches}")
            print(f"   âœ”ï¸ Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Ø¶Ø¨Ø§Ø¨ÙŠØ©: {fuzzy_matches}")
            if rl_matches > 0:
                print(f"   âœ”ï¸ Ù…Ø·Ø§Ø¨Ù‚Ø§Øª RL: {rl_matches}")
            print(f"   âš ï¸ ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚: {unmatched}")
            
            return self.merged_results
            
        except Exception as e:
            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø·Ø£
            if self.use_advanced_features and self.logger and AUDIT_LOGGER_AVAILABLE:
                try:
                    self.logger.log_error(
                        error_type=type(e).__name__,
                        error_message=str(e),
                        context={
                            'function': 'match_with_bank',
                            'time_window_days': time_window_days,
                            'use_record_linkage': use_record_linkage
                        }
                    )
                except:
                    pass
            
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©: {str(e)}")
            raise
    
    def _basic_matching(self, time_window_days: int) -> pd.DataFrame:
        """
        Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Exact + Fuzzy ÙÙ‚Ø·)
        Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ØªØªÙˆÙØ± Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        """
        results = []
        
        for idx, award_row in self.awards_data.iterrows():
            result = {
                'OwnerName': award_row.get('OwnerName', ''),
                'Race': award_row.get('Race', ''),
                'Season': award_row.get('Season', ''),
                'AwardAmount': award_row.get('AwardAmount', 0),
                'EntryDate': award_row.get('EntryDate', None),
                'BankDate': None,
                'BankReference': None,
                'MatchScore': 0,
                'StatusFlag': '',
                'ReasonText': '',
                'MatchType': 'No Match'
            }
            
            owner_name = award_row.get('OwnerName_norm', '')
            award_amount = award_row.get('AwardAmount', 0)
            entry_date = award_row.get('EntryDate', None)
            
            if pd.isna(award_amount) or pd.isna(entry_date):
                result['StatusFlag'] = 'âš ï¸'
                result['ReasonText'] = 'Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ø§Ù‚ØµØ©'
                results.append(result)
                continue
            
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ
            best_match = None
            best_score = 0
            
            for _, bank_row in self.bank_data.iterrows():
                bank_amount = bank_row.get('BankAmount', 0)
                bank_date = bank_row.get('BankDate', None)
                bank_name = bank_row.get('BankName_norm', '')
                
                if pd.isna(bank_amount) or pd.isna(bank_date):
                    continue
                
                # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¨Ù„Øº
                if abs(award_amount - bank_amount) > 0.01:
                    continue
                
                # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†Ø§ÙØ°Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©
                date_diff = abs((entry_date - bank_date).days)
                if date_diff > time_window_days:
                    continue
                
                # Ø§Ù„Ø·Ø¨Ù‚Ø© 1: Ù…Ø·Ø§Ø¨Ù‚Ø© ØªØ§Ù…Ø©
                if owner_name == bank_name:
                    best_match = bank_row
                    best_score = 100
                    result['MatchType'] = 'Exact'
                    break
                
                # Ø§Ù„Ø·Ø¨Ù‚Ø© 2: Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¶Ø¨Ø§Ø¨ÙŠØ©
                fuzzy_score = fuzz.ratio(owner_name, bank_name)
                if fuzzy_score >= 90 and fuzzy_score > best_score:
                    best_match = bank_row
                    best_score = fuzzy_score
                    result['MatchType'] = 'Fuzzy'
            
            if best_match is not None:
                result['BankDate'] = best_match.get('BankDate', None)
                result['BankReference'] = best_match.get('BankReference', '')
                result['MatchScore'] = best_score
                result['StatusFlag'] = 'âœ…'
                result['ReasonText'] = f'Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¨Ù†Ø³Ø¨Ø© {best_score}%'
            else:
                result['StatusFlag'] = 'âš ï¸'
                result['ReasonText'] = 'Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø·Ø§Ø¨Ù‚Ø© ÙÙŠ ÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ'
            
            results.append(result)
        
        return pd.DataFrame(results)
    
    def detect_internal_duplicates(self) -> pd.DataFrame:
        """
        ÙƒØ´Ù Ø§Ù„ØµØ±Ù Ø§Ù„Ù…ÙƒØ±Ø± Ø¯Ø§Ø®Ù„ Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬ÙˆØ§Ø¦Ø²
        
        Returns:
            DataFrame Ø¨Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©
        """
        if self.merged_results is None:
            raise ValueError("ÙŠØ¬Ø¨ Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¹ Ø§Ù„Ø¨Ù†Ùƒ Ø£ÙˆÙ„Ø§Ù‹")
        
        df = self.merged_results.copy()
        
        # ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨: Ø§Ù„Ø§Ø³Ù…ØŒ Ø§Ù„Ø³Ø¨Ø§Ù‚ØŒ Ø§Ù„Ù…Ø¨Ù„Øº
        grouped = df.groupby(['OwnerName', 'Race', 'AwardAmount'])
        
        for name, group in grouped:
            if len(group) > 1:
                # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
                dates = group['EntryDate'].dropna().unique()
                
                if len(dates) > 1:
                    # ØªÙƒØ±Ø§Ø± Ù…Ø´ØªØ¨Ù‡ - Ù†ÙØ³ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨ØªÙˆØ§Ø±ÙŠØ® Ù…Ø®ØªÙ„ÙØ©
                    indices = group.index
                    df.loc[indices, 'StatusFlag'] = 'âš ï¸'
                    df.loc[indices, 'ReasonText'] = df.loc[indices, 'ReasonText'] + ' | ØµØ±Ù Ù…ÙƒØ±Ø± Ù…Ø´ØªØ¨Ù‡'
        
        # ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙƒØ±Ø§Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ Ø§Ù„Ø¨Ù†ÙƒÙŠ
        if 'BankReference' in df.columns:
            bank_refs = df['BankReference'].dropna()
            duplicate_refs = bank_refs[bank_refs.duplicated(keep=False)]
            
            if len(duplicate_refs) > 0:
                for ref in duplicate_refs.unique():
                    indices = df[df['BankReference'] == ref].index
                    df.loc[indices, 'StatusFlag'] = 'âŒ'
                    df.loc[indices, 'ReasonText'] = df.loc[indices, 'ReasonText'] + ' | ØµØ±Ù Ù…ÙƒØ±Ø± Ù…Ø¤ÙƒØ¯ (Ù…Ø±Ø¬Ø¹ Ø¨Ù†ÙƒÙŠ Ù…ÙƒØ±Ø±)'
        
        self.merged_results = df
        return df
    
    def calculate_statistics(self) -> Dict[str, Any]:
        """
        Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©
        
        Returns:
            Ù‚Ø§Ù…ÙˆØ³ Ø¨Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        """
        if self.merged_results is None:
            return {}
        
        df = self.merged_results
        
        total_records = len(df)
        matched_ok = len(df[df['StatusFlag'] == 'âœ…'])
        suspected = len(df[df['StatusFlag'] == 'âš ï¸'])
        confirmed_duplicate = len(df[df['StatusFlag'] == 'âŒ'])
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…ÙˆØ³Ù…
        seasons_stats = {}
        if 'Season' in df.columns:
            seasons_stats = df.groupby('Season').size().to_dict()
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ø³Ø¨Ø§Ù‚
        races_stats = {}
        if 'Race' in df.columns:
            races_stats = df.groupby('Race').size().to_dict()
        
        self.statistics = {
            'total_records': total_records,
            'matched_ok': matched_ok,
            'suspected': suspected,
            'confirmed_duplicate': confirmed_duplicate,
            'match_rate': (matched_ok / total_records * 100) if total_records > 0 else 0,
            'seasons': seasons_stats,
            'races': races_stats,
            'total_amount': df['AwardAmount'].sum() if 'AwardAmount' in df.columns else 0
        }
        
        return self.statistics
    
    def export_report(self, output_path: str = None) -> str:
        """
        ØªØµØ¯ÙŠØ± Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¥Ù„Ù‰ Excel (Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…ØªÙ‚Ø¯Ù… v2.0)
        
        Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©:
        - Sheet 1: Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„Ø©
        - Sheet 2: Ø¬Ø¯ÙˆÙ„ Pivot ØªÙØ§Ø¹Ù„ÙŠ
        - Sheet 3: Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©
        - Sheet 4: Audit Log (Ø³Ø¬Ù„ Ø§Ù„ØªØ´ØºÙŠÙ„)
        
        Args:
            output_path: Ù…Ø³Ø§Ø± Ø§Ù„Ø­ÙØ¸
            
        Returns:
            Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­ÙÙˆØ¸
        """
        if self.merged_results is None:
            raise ValueError("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù„Ù„ØªØµØ¯ÙŠØ±")
        
        if output_path is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_path = f'outputs/camel_awards_report_{timestamp}.xlsx'
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        
        print(f"\nğŸ“Š ØªØµØ¯ÙŠØ± Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…...")
        
        try:
            with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:
                workbook = writer.book
                
                # ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø§Ù„Ø£Ù„ÙˆØ§Ù†
                green_format = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100'})
                yellow_format = workbook.add_format({'bg_color': '#FFEB9C', 'font_color': '#9C6500'})
                red_format = workbook.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006'})
                header_format = workbook.add_format({
                    'bold': True,
                    'bg_color': '#4472C4',
                    'font_color': 'white',
                    'align': 'center'
                })
                
                # Sheet 1: Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                self.merged_results.to_excel(writer, sheet_name='Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„Ø©', index=False)
                worksheet = writer.sheets['Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„Ø©']
                
                # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø´Ø±Ø·ÙŠ
                if 'StatusFlag' in self.merged_results.columns:
                    status_col = self.merged_results.columns.get_loc('StatusFlag')
                    for row_num, status in enumerate(self.merged_results['StatusFlag'], start=1):
                        if status == 'âœ…':
                            worksheet.write(row_num, status_col, status, green_format)
                        elif status == 'âš ï¸':
                            worksheet.write(row_num, status_col, status, yellow_format)
                        elif status == 'âŒ':
                            worksheet.write(row_num, status_col, status, red_format)
                
                print(f"   âœ… Sheet 1: Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„Ø© ({len(self.merged_results):,} Ø³Ø¬Ù„)")
                
                # Sheet 2: Ù…Ù„Ø®Øµ Pivot
                if 'Season' in self.merged_results.columns and 'Race' in self.merged_results.columns:
                    try:
                        pivot = pd.pivot_table(
                            self.merged_results,
                            values='AwardAmount',
                            index=['Season', 'Race'],
                            columns='StatusFlag',
                            aggfunc='count',
                            fill_value=0
                        )
                        pivot.to_excel(writer, sheet_name='Ù…Ù„Ø®Øµ Pivot')
                        print(f"   âœ… Sheet 2: Ø¬Ø¯ÙˆÙ„ Pivot")
                    except Exception as e:
                        print(f"   âš ï¸ ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Pivot - {str(e)}")
                
                # Sheet 3: Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                if self.statistics:
                    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¥Ù„Ù‰ DataFrame Ø£ÙƒØ«Ø± ÙˆØ¶ÙˆØ­Ø§Ù‹
                    stats_rows = []
                    for key, value in self.statistics.items():
                        if not isinstance(value, dict):
                            stats_rows.append({
                                'Ø§Ù„Ù…Ø¤Ø´Ø±': key,
                                'Ø§Ù„Ù‚ÙŠÙ…Ø©': value
                            })
                    
                    stats_df = pd.DataFrame(stats_rows)
                    stats_df.to_excel(writer, sheet_name='Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª', index=False)
                    
                    # ØªÙ†Ø³ÙŠÙ‚ Ø±Ø£Ø³ Ø§Ù„Ø¬Ø¯ÙˆÙ„
                    worksheet_stats = writer.sheets['Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª']
                    for col_num, value in enumerate(stats_df.columns.values):
                        worksheet_stats.write(0, col_num, value, header_format)
                    
                    print(f"   âœ… Sheet 3: Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ({len(stats_rows)} Ù…Ø¤Ø´Ø±)")
                
                # Sheet 4: Audit Log (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹)
                if self.use_advanced_features and self.logger and AUDIT_LOGGER_AVAILABLE and self.current_run_id:
                    try:
                        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªØ´ØºÙŠÙ„
                        run_details = self.logger.get_run_details(self.current_run_id)
                        run_info = run_details.get('run_info', {})
                        
                        if run_info:
                            audit_rows = [
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'RunID', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': self.current_run_id},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ´ØºÙŠÙ„', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': run_info.get('Timestamp', 'N/A')},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¬ÙˆØ§Ø¦Ø²', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': run_info.get('TotalAwards', 0)},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Exact', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': run_info.get('ExactMatches', 0)},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Fuzzy', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': run_info.get('FuzzyMatches', 0)},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'Ù…Ø·Ø§Ø¨Ù‚Ø§Øª RL', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': run_info.get('RLMatches', 0)},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': run_info.get('UnmatchedAwards', 0)},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ° (Ø«)', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': f"{run_info.get('ExecutionTimeSeconds', 0):.2f}"},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': run_info.get('UserName', 'System')},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'Ø§Ù„Ø­Ø§Ù„Ø©', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': run_info.get('Status', 'N/A')}
                            ]
                            
                            audit_df = pd.DataFrame(audit_rows)
                            audit_df.to_excel(writer, sheet_name='Audit Log', index=False)
                            
                            # ØªÙ†Ø³ÙŠÙ‚ Ø±Ø£Ø³ Ø§Ù„Ø¬Ø¯ÙˆÙ„
                            worksheet_audit = writer.sheets['Audit Log']
                            for col_num, value in enumerate(audit_df.columns.values):
                                worksheet_audit.write(0, col_num, value, header_format)
                            
                            print(f"   âœ… Sheet 4: Audit Log (RunID: {self.current_run_id[:8]}...)")
                    
                    except Exception as e:
                        print(f"   âš ï¸ ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø¥Ø¶Ø§ÙØ© Audit Log - {str(e)}")
            
            print(f"\nâœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØµØ¯ÙŠØ±: {str(e)}")
            raise
    
    def filter_results(
        self, 
        season: Optional[str] = None,
        race: Optional[str] = None,
        status: Optional[str] = None,
        participant: Optional[str] = None
    ) -> pd.DataFrame:
        """
        ÙÙ„ØªØ±Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        
        Args:
            season: Ø§Ù„Ù…ÙˆØ³Ù…
            race: Ø§Ù„Ø³Ø¨Ø§Ù‚
            status: Ø§Ù„Ø­Ø§Ù„Ø©
            participant: Ø§Ù„Ù…Ø´Ø§Ø±Ùƒ
            
        Returns:
            DataFrame Ù…ÙÙ„ØªØ±
        """
        if self.merged_results is None:
            return pd.DataFrame()
        
        df = self.merged_results.copy()
        
        if season and 'Season' in df.columns:
            df = df[df['Season'] == season]
        
        if race and 'Race' in df.columns:
            df = df[df['Race'] == race]
        
        if status and 'StatusFlag' in df.columns:
            df = df[df['StatusFlag'] == status]
        
        if participant and 'OwnerName' in df.columns:
            df = df[df['OwnerName'].str.contains(participant, case=False, na=False)]
        
        return df
