# -*- coding: utf-8 -*-
"""
ğŸ† Ù…Ø­Ù„Ù„ Ø¬ÙˆØ§Ø¦Ø² Ø³Ø¨Ø§Ù‚Ø§Øª Ø§Ù„Ù‡Ø¬Ù†
Camel Race Awards Analyzer
================================
Ù†Ø¸Ø§Ù… Ù…ØªÙ‚Ø¯Ù… Ù„ØªØ­Ù„ÙŠÙ„ ÙˆÙ…Ø·Ø§Ø¨Ù‚Ø© Ø¬ÙˆØ§Ø¦Ø² Ø³Ø¨Ø§Ù‚Ø§Øª Ø§Ù„Ù‡Ø¬Ù† Ù…Ø¹ ÙƒØ´ÙˆÙØ§Øª Ø§Ù„Ø¨Ù†Ùƒ
ÙˆØ§ÙƒØªØ´Ø§Ù Ø§Ù„ØµØ±Ù Ø§Ù„Ù…ÙƒØ±Ø± ÙˆØ§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© v2.0:
- Ù…Ø·Ø§Ø¨Ù‚Ø© 3 Ø·Ø¨Ù‚Ø§Øª: Exact â†’ Fuzzy â†’ Record Linkage
- ØªØ³Ø¬ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù…Ø¹ Audit Trail
- Ø£Ø¯Ø§Ø¡ Ù…Ø­Ø³Ù‘Ù† Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime, timedelta
from pathlib import Path
import re
from rapidfuzz import fuzz
import warnings
import time

warnings.filterwarnings('ignore')

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
try:
    from core.advanced_matcher import AdvancedMatcher
    ADVANCED_MATCHER_AVAILABLE = True
except ImportError:
    ADVANCED_MATCHER_AVAILABLE = False
    warnings.warn("âš ï¸ Advanced Matcher ØºÙŠØ± Ù…ØªÙˆÙØ± - Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©")

try:
    from core.audit_logger import AuditLogger
    AUDIT_LOGGER_AVAILABLE = True
except ImportError:
    AUDIT_LOGGER_AVAILABLE = False
    warnings.warn("âš ï¸ Audit Logger ØºÙŠØ± Ù…ØªÙˆÙØ± - Ù„Ù† ÙŠØªÙ… Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„Ø§Øª")

try:
    from core.performance_optimizer import PerformanceOptimizer, recommend_optimizer_settings
    PERFORMANCE_OPTIMIZER_AVAILABLE = True
except ImportError:
    PERFORMANCE_OPTIMIZER_AVAILABLE = False
    warnings.warn("âš ï¸ Performance Optimizer ØºÙŠØ± Ù…ØªÙˆÙØ± - Ø§Ø³ØªØ®Ø¯Ø§Ù… pandas Ø§Ù„Ø¹Ø§Ø¯ÙŠ")


class CamelAwardsAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø¬ÙˆØ§Ø¦Ø² Ø³Ø¨Ø§Ù‚Ø§Øª Ø§Ù„Ù‡Ø¬Ù† - Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…ØªÙ‚Ø¯Ù… v2.0"""
    
    def __init__(self, use_advanced_features: bool = True):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ù„Ù„
        
        Args:
            use_advanced_features: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© (Ù…Ø·Ø§Ø¨Ù‚Ø© 3 Ø·Ø¨Ù‚Ø§ØªØŒ ØªØ³Ø¬ÙŠÙ„ØŒ Ø£Ø¯Ø§Ø¡ Ù…Ø­Ø³Ù‘Ù†)
        """
        # Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        self.awards_data = None
        self.bank_data = None
        self.merged_results = None
        self.statistics = {}
        
        # Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        self.use_advanced_features = use_advanced_features
        self.matcher = None
        self.logger = None
        self.optimizer = None
        self.current_run_id = None
        
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        if use_advanced_features:
            if ADVANCED_MATCHER_AVAILABLE:
                self.matcher = AdvancedMatcher(fuzzy_threshold=90)
                print("âœ… Advanced Matcher Ù…ÙØ¹Ù‘Ù„")
            
            if AUDIT_LOGGER_AVAILABLE:
                self.logger = AuditLogger(log_dir="outputs/audit_logs")
                print("âœ… Audit Logger Ù…ÙØ¹Ù‘Ù„")
            
            # Performance Optimizer ÙŠØªÙ… ØªÙ‡ÙŠØ¦ØªÙ‡ Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©
            if PERFORMANCE_OPTIMIZER_AVAILABLE:
                print("âœ… Performance Optimizer Ù…ØªØ§Ø­")
        
    def normalize_text(self, text: str) -> str:
        """
        ØªØ·Ø¨ÙŠØ¹ ÙˆØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ
        
        Args:
            text: Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ·Ø¨ÙŠØ¹Ù‡
            
        Returns:
            Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø·Ø¨Ù‘Ø¹
        """
        if pd.isna(text) or not isinstance(text, str):
            return ""

        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø¥Ù„Ù‰ Ù†Øµ ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙˆØ§ØµÙ„ Ø§Ù„Ø³ÙÙ„ÙŠØ© ÙƒÙ…Ø³Ø§ÙØ§Øª
        text = str(text).replace('_', ' ')
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
        text = re.sub(r'\s+', ' ', text).strip()

        # ØªÙˆØ­ÙŠØ¯ Unicode (ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)
        text = text.replace('Ø£', 'Ø§').replace('Ø¥', 'Ø§').replace('Ø¢', 'Ø§')
        text = text.replace('Ø©', 'Ù‡')
        text = text.replace('Ù‰', 'ÙŠ')
        
        # ØªØ­ÙˆÙŠÙ„ Ù„Ø£Ø­Ø±Ù ØµØºÙŠØ±Ø©
        text = text.lower()
        
        return text
    
    def normalize_column_names(self, df: pd.DataFrame, context: str = "generic") -> pd.DataFrame:
        """
        ØªÙˆØ­ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        
        Args:
            df: DataFrame Ø§Ù„Ù…Ø±Ø§Ø¯ ØªÙˆØ­ÙŠØ¯ Ø£Ø¹Ù…Ø¯ØªÙ‡
            context: Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (awards / bank / generic)
            
        Returns:
            DataFrame Ø¨Ø£Ø¹Ù…Ø¯Ø© Ù…ÙˆØ­Ø¯Ø©
        """
        df_copy = df.copy()
        df_copy.columns = [self.normalize_text(col) for col in df_copy.columns]

        def canonical(label: str) -> str:
            return self.normalize_text(label).replace(' ', '')

        # Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        base_groups = {
            'Season': ['season', 'Ø§Ù„Ù…ÙˆØ³Ù…', 'Ù…ÙˆØ³Ù…'],
            'Race': ['race', 'Ø§Ù„Ø³Ø¨Ø§Ù‚', 'Ø³Ø¨Ø§Ù‚', 'race name', 'Ø§Ø³Ù… Ø§Ù„Ø³Ø¨Ø§Ù‚'],
            'AwardAmount': ['award amount', 'awardamount', 'amount', 'Ø§Ù„Ù…Ø¨Ù„Øº', 'Ù…Ø¨Ù„Øº', 'Ø§Ù„Ù‚ÙŠÙ…Ø©', 'Ø§Ù„Ø¬Ø§Ø¦Ø²Ø©', 'value'],
            'EntryDate': ['entrydate', 'entry date', 'date', 'Ø§Ù„ØªØ§Ø±ÙŠØ®', 'ØªØ§Ø±ÙŠØ®', 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„', 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø³Ø¨Ø§Ù‚']
        }

        awards_groups = {
            'OwnerName': ['ownername', 'Ø§Ø³Ù… Ø§Ù„Ù…Ø§Ù„Ùƒ', 'Ø§Ù„Ù…Ø§Ù„Ùƒ', 'Ø§Ù„Ø§Ø³Ù…', 'owner name']
        }

        bank_groups = {
            'BankName': ['bankname', 'Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙÙŠØ¯', 'Ø§Ù„Ù…Ø³ØªÙÙŠØ¯', 'beneficiary', 'beneficiary name', 'name', 'ownername'],
            'BankAmount': ['bankamount', 'Ù…Ø¨Ù„Øº Ø§Ù„ØªØ­ÙˆÙŠÙ„', 'payment amount', 'amount', 'Ø§Ù„Ù‚ÙŠÙ…Ø©', 'value'],
            'BankDebit': ['bankdebit', 'debit', 'debitamount', 'debit amount', 'Ù…Ø¯ÙŠÙ†'],
            'BankCredit': ['bankcredit', 'credit', 'creditamount', 'credit amount', 'Ø¯Ø§Ø¦Ù†'],
            'BankDate': ['bankdate', 'ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­ÙˆÙŠÙ„', 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯ÙØ¹', 'payment date', 'transaction date'],
            'BankValueDate': ['value date', 'valuedate'],
            'BankReference': ['bankreference', 'bank ref'],
            'BankRequestReference': ['request reference'],
            'BankOperationReference': ['reference', 'Ø§Ù„Ù…Ø±Ø¬Ø¹', 'Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø¬Ø¹', 'Ø±Ù‚Ù… Ø§Ù„Ø¹Ù…Ù„ÙŠØ©'],
            'AwardReference': ['award ref', 'award reference'],
            'AwardReferenceLong': ['award ref 10 digits', 'award ref 10digits', 'award reference 10 digits']
        }

        def build_mapping(groups: Dict[str, List[str]]) -> Dict[str, str]:
            mapping: Dict[str, str] = {}
            for target, aliases in groups.items():
                for alias in aliases:
                    mapping[canonical(alias)] = target
            return mapping

        mapping = build_mapping(base_groups)

        if context == 'awards':
            mapping.update(build_mapping(awards_groups))
        elif context == 'bank':
            mapping.update(build_mapping(bank_groups))
        else:
            mapping.update(build_mapping(awards_groups))
            mapping.update(build_mapping(bank_groups))

        rename_map: Dict[str, str] = {}
        for col in df_copy.columns:
            key = canonical(col)
            if key in mapping:
                rename_map[col] = mapping[key]

        df_copy.rename(columns=rename_map, inplace=True)

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¨Ù†Ùƒ: Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ³Ù…ÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø­Ø±Ø¬Ø©
        if context == 'bank':
            if 'BankName' not in df_copy.columns and 'OwnerName' in df_copy.columns:
                df_copy.rename(columns={'OwnerName': 'BankName'}, inplace=True)

            if 'BankDate' not in df_copy.columns:
                for fallback in ['transaction date', 'value date']:
                    if fallback in df_copy.columns:
                        df_copy.rename(columns={fallback: 'BankDate'}, inplace=True)
                        break

        return df_copy
    
    def load_awards_files(self, files: List[Any]) -> pd.DataFrame:
        """
        ØªØ­Ù…ÙŠÙ„ ÙˆØ¯Ù…Ø¬ Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬ÙˆØ§Ø¦Ø²
        
        Args:
            files: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ù…Ù„ÙØ§Øª Excel Ù„Ù„Ø¬ÙˆØ§Ø¦Ø²
            
        Returns:
            DataFrame Ù…ÙˆØ­Ø¯ Ù„Ù„Ø¬ÙˆØ§Ø¦Ø²
        """
        all_data = []
        
        for file in files:
            try:
                # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
                if hasattr(file, 'name'):
                    if file.name.endswith('.csv'):
                        df = pd.read_csv(file)
                    else:
                        df = pd.read_excel(file)
                else:
                    df = pd.read_excel(file)
                
                # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
                df = self.normalize_column_names(df, context="awards")
                
                all_data.append(df)
                
            except Exception as e:
                print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {str(e)}")
                continue
        
        if not all_data:
            raise ValueError("Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£ÙŠ Ù…Ù„ÙØ§Øª Ø¨Ù†Ø¬Ø§Ø­")
        
        # Ø¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
        self.awards_data = pd.concat(all_data, ignore_index=True)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù…Ø·Ø¨Ù‘Ø¹
        if 'OwnerName' in self.awards_data.columns:
            self.awards_data['OwnerName_norm'] = self.awards_data['OwnerName'].apply(self.normalize_text)
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
        if 'EntryDate' in self.awards_data.columns:
            self.awards_data['EntryDate'] = pd.to_datetime(
                self.awards_data['EntryDate'], 
                errors='coerce',
                dayfirst=True
            )
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ù„Øº Ù„Ø£Ø±Ù‚Ø§Ù…
        if 'AwardAmount' in self.awards_data.columns:
            self.awards_data['AwardAmount'] = pd.to_numeric(
                self.awards_data['AwardAmount'], 
                errors='coerce'
            )
        
        return self.awards_data
    
    def load_bank_statement(self, file: Any) -> pd.DataFrame:
        """
        ØªØ­Ù…ÙŠÙ„ ÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ
        
        Args:
            file: Ù…Ù„Ù Excel Ù„ÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ
            
        Returns:
            DataFrame Ù„ÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ
        """
        try:
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
            if hasattr(file, 'name'):
                if file.name.endswith('.csv'):
                    df = pd.read_csv(file)
                else:
                    # Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© Ù…Ù† ØµÙÙˆÙ Ù…Ø®ØªÙ„ÙØ© (ÙÙŠ Ø­Ø§Ù„ ÙƒØ§Ù†Øª headers ÙÙŠ ØµÙ ØºÙŠØ± Ø§Ù„Ø£ÙˆÙ„)
                    df = pd.read_excel(file, header=None)
                    
                    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØµÙ Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ headers
                    header_row = 0
                    for i in range(min(10, len(df))):
                        row_values = df.iloc[i].astype(str).str.lower()
                        if any('name' in str(v) or 'Ø§Ø³Ù…' in str(v) or 'amount' in str(v) or 'Ù…Ø¨Ù„Øº' in str(v) for v in row_values):
                            header_row = i
                            break
                    
                    # Ø¥Ø¹Ø§Ø¯Ø© Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ù…Ø¹ Ø§Ù„Ù€ header Ø§Ù„ØµØ­ÙŠØ­
                    if header_row > 0:
                        df = pd.read_excel(file, header=header_row)
                    else:
                        df = pd.read_excel(file)
            else:
                df = pd.read_excel(file)
            
            # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            df = self.normalize_column_names(df, context="bank")

            # Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¯ÙŠÙ† ÙˆØ§Ù„Ø¯Ø§Ø¦Ù† Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙÙŠ Ø§Ø´ØªÙ‚Ø§Ù‚ Ø§Ù„Ù…Ø¨Ù„Øº
            bank_debit = None
            bank_credit = None

            if 'BankDebit' in df.columns:
                df['BankDebit'] = pd.to_numeric(df['BankDebit'], errors='coerce')
                bank_debit = df['BankDebit']
            else:
                for col in df.columns:
                    if str(col).lower() == 'debit':
                        bank_debit = pd.to_numeric(df[col], errors='coerce')
                        df['BankDebit'] = bank_debit
                        break

            if 'BankCredit' in df.columns:
                df['BankCredit'] = pd.to_numeric(df['BankCredit'], errors='coerce')
                bank_credit = df['BankCredit']
            else:
                for col in df.columns:
                    if str(col).lower() == 'credit':
                        bank_credit = pd.to_numeric(df[col], errors='coerce')
                        df['BankCredit'] = bank_credit
                        break

            # Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø¨Ù„Øº Ø§Ù„Ø¨Ù†ÙƒÙŠ Ø£Ùˆ Ø§Ø´ØªÙ‚Ø§Ù‚Ù‡ Ù…Ù† Ø§Ù„Ù…Ø¯ÙŠÙ† ÙˆØ§Ù„Ø¯Ø§Ø¦Ù†
            has_bank_amount = 'BankAmount' in df.columns
            if has_bank_amount:
                existing_amount = pd.to_numeric(df['BankAmount'], errors='coerce')
                if existing_amount.notna().any():
                    df['BankAmount'] = existing_amount
                else:
                    df.drop(columns=['BankAmount'], inplace=True)
                    has_bank_amount = False

            if not has_bank_amount:
                computed_amount = None
                if bank_debit is not None and bank_credit is not None:
                    computed_amount = bank_debit.fillna(0) - bank_credit.fillna(0)
                elif bank_debit is not None:
                    computed_amount = bank_debit
                elif bank_credit is not None:
                    computed_amount = bank_credit

                if computed_amount is not None:
                    df['BankAmount'] = computed_amount

            if 'BankAmount' in df.columns:
                df['BankAmount'] = pd.to_numeric(df['BankAmount'], errors='coerce')

            # ØªØ¹ÙŠÙŠÙ† ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ù†Ùƒ Ù…Ù† Ø£Ø¹Ù…Ø¯Ø© Ø¨Ø¯ÙŠÙ„Ø© Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
            if 'BankDate' not in df.columns:
                if 'BankValueDate' in df.columns:
                    df['BankDate'] = df['BankValueDate']
                else:
                    lower_map = {str(col).lower(): col for col in df.columns}
                    for fallback in ['transaction date', 'value date']:
                        if fallback in lower_map:
                            df['BankDate'] = df[lower_map[fallback]]
                            break
            
            self.bank_data = df
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù…Ø·Ø¨Ù‘Ø¹
            if 'BankName' in self.bank_data.columns:
                self.bank_data['BankName_norm'] = self.bank_data['BankName'].apply(self.normalize_text)
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
            if 'BankDate' in self.bank_data.columns:
                self.bank_data['BankDate'] = pd.to_datetime(
                    self.bank_data['BankDate'], 
                    errors='coerce',
                    dayfirst=True
                )
            if 'BankValueDate' in self.bank_data.columns:
                self.bank_data['BankValueDate'] = pd.to_datetime(
                    self.bank_data['BankValueDate'],
                    errors='coerce',
                    dayfirst=True
                )
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ù„Øº Ù„Ø£Ø±Ù‚Ø§Ù…
            if 'BankAmount' in self.bank_data.columns:
                amount_data = self.bank_data['BankAmount']
                if isinstance(amount_data, pd.DataFrame):
                    amount_data = amount_data.iloc[:, 0]
                self.bank_data['BankAmount'] = pd.to_numeric(
                    amount_data,
                    errors='coerce'
                )

            for col in ['BankDebit', 'BankCredit']:
                if col in self.bank_data.columns:
                    col_data = self.bank_data[col]
                    if isinstance(col_data, pd.DataFrame):
                        col_data = col_data.iloc[:, 0]
                    self.bank_data[col] = pd.to_numeric(col_data, errors='coerce')
            
            return self.bank_data
            
        except Exception as e:
            raise ValueError(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ ÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ: {str(e)}")
    
    def match_with_bank(
        self,
        time_window_days: int = 7,
        use_record_linkage: bool = False,
        files_info: Optional[Dict[str, List[str]]] = None
    ) -> pd.DataFrame:
        """
        Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬ÙˆØ§Ø¦Ø² Ù…Ø¹ ÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ (Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…ØªÙ‚Ø¯Ù… v2.0)
        
        Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©:
        - Ù…Ø·Ø§Ø¨Ù‚Ø© 3 Ø·Ø¨Ù‚Ø§Øª: Exact â†’ Fuzzy â†’ Record Linkage
        - ØªØ³Ø¬ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù…Ø¹ Audit Trail
        - Ø£Ø¯Ø§Ø¡ Ù…Ø­Ø³Ù‘Ù† Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
        
        Args:
            time_window_days: Ù†Ø§ÙØ°Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø²Ù…Ù†ÙŠ Ø¨Ø§Ù„Ø£ÙŠØ§Ù…
            use_record_linkage: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø·Ø§Ø¨Ù‚Ø© Record Linkage (Ù„Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„ØµØ¹Ø¨Ø©)
            files_info: Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù„ØªØ³Ø¬ÙŠÙ„ (dict Ù…Ø¹ Ù…ÙØ§ØªÙŠØ­ 'awards_files', 'bank_file')
            
        Returns:
            DataFrame Ø¨Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        """
        if self.awards_data is None or self.bank_data is None:
            raise ValueError("ÙŠØ¬Ø¨ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬ÙˆØ§Ø¦Ø² ÙˆÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ Ø£ÙˆÙ„Ø§Ù‹")
        
        print(f"\nğŸ” Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©...")
        print(f"   ğŸ“Š Ø¬ÙˆØ§Ø¦Ø²: {len(self.awards_data):,} Ø³Ø¬Ù„")
        print(f"   ğŸ¦ Ø¨Ù†Ùƒ: {len(self.bank_data):,} Ø³Ø¬Ù„")
        print(f"   â° Ù†Ø§ÙØ°Ø© Ø²Ù…Ù†ÙŠØ©: Â±{time_window_days} ÙŠÙˆÙ…")
        
        start_time = time.time()
        
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
            if self.use_advanced_features and self.matcher and ADVANCED_MATCHER_AVAILABLE:
                print(f"   âœ¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… Advanced Matcher (3 Ø·Ø¨Ù‚Ø§Øª)")
                
                # Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª
                matched_df, unmatched_df = self.matcher.match_all_layers(
                    awards_df=self.awards_data,
                    bank_df=self.bank_data,
                    time_window_days=time_window_days,
                    use_record_linkage=use_record_linkage
                )
                
                # Ø¥Ø¶Ø§ÙØ© Ø£Ø¹Ù…Ø¯Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„ØªÙˆØ§ÙÙ‚
                if len(matched_df) > 0:
                    matched_df['StatusFlag'] = 'âœ…'
                    matched_df['ReasonText'] = matched_df.apply(
                        lambda x: f"Ù…Ø·Ø§Ø¨Ù‚Ø© {x['MatchType']} Ø¨Ù†Ø³Ø¨Ø© {x['MatchScore']}%",
                        axis=1
                    )
                
                if len(unmatched_df) > 0:
                    unmatched_df['MatchType'] = 'No Match'
                    unmatched_df['MatchScore'] = 0
                    unmatched_df['BankDate'] = None
                    unmatched_df['BankReference'] = None
                    unmatched_df['StatusFlag'] = 'âš ï¸'
                    unmatched_df['ReasonText'] = 'Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø·Ø§Ø¨Ù‚Ø©'
                
                # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                self.merged_results = pd.concat([matched_df, unmatched_df], ignore_index=True)
                
            else:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù‚Ø¯ÙŠÙ…)
                print(f"   âš ï¸ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Exact + Fuzzy ÙÙ‚Ø·)")
                self.merged_results = self._basic_matching(time_window_days)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            execution_time = time.time() - start_time
            
            exact_matches = len(self.merged_results[self.merged_results['MatchType'] == 'Exact'])
            fuzzy_matches = len(self.merged_results[self.merged_results['MatchType'] == 'Fuzzy'])
            rl_matches = len(self.merged_results[self.merged_results['MatchType'] == 'RecordLinkage'])
            unmatched = len(self.merged_results[self.merged_results['MatchType'] == 'No Match'])
            
            self.statistics = {
                'total_awards': len(self.awards_data),
                'total_bank_records': len(self.bank_data),
                'exact_matches': exact_matches,
                'fuzzy_matches': fuzzy_matches,
                'rl_matches': rl_matches,
                'unmatched_awards': unmatched,
                'execution_time': execution_time,
                'time_window_days': time_window_days,
                'use_record_linkage': use_record_linkage
            }
            
            # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Audit Logger
            if self.use_advanced_features and self.logger and AUDIT_LOGGER_AVAILABLE:
                try:
                    # ØªØ­Ø¯ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª
                    if files_info:
                        awards_files = files_info.get('awards_files', ['unknown'])
                        bank_file = files_info.get('bank_file', 'unknown')
                    else:
                        awards_files = ['multiple_files']
                        bank_file = 'bank_statement.xlsx'
                    
                    self.current_run_id = self.logger.log_analysis_run(
                        awards_files=awards_files,
                        bank_file=bank_file,
                        statistics=self.statistics,
                        time_window_days=time_window_days,
                        fuzzy_threshold=90,
                        use_record_linkage=use_record_linkage,
                        execution_time=execution_time,
                        user_name="System",
                        status="Success"
                    )
                    
                    # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø§Øª
                    if len(self.merged_results[self.merged_results['MatchType'] != 'No Match']) > 0:
                        matches_only = self.merged_results[self.merged_results['MatchType'] != 'No Match']
                        self.logger.log_matches(self.current_run_id, matches_only)
                    
                    print(f"   ğŸ“ ØªÙ… Ø§Ù„ØªØ³Ø¬ÙŠÙ„: RunID={self.current_run_id[:8]}...")
                    
                except Exception as e:
                    print(f"   âš ï¸ ØªØ­Ø°ÙŠØ±: ÙØ´Ù„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ - {str(e)}")
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            print(f"\nâœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© ÙÙŠ {execution_time:.2f} Ø«Ø§Ù†ÙŠØ©")
            print(f"   âœ”ï¸ Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Ø­ØªÙ…ÙŠØ©: {exact_matches}")
            print(f"   âœ”ï¸ Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Ø¶Ø¨Ø§Ø¨ÙŠØ©: {fuzzy_matches}")
            if rl_matches > 0:
                print(f"   âœ”ï¸ Ù…Ø·Ø§Ø¨Ù‚Ø§Øª RL: {rl_matches}")
            print(f"   âš ï¸ ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚: {unmatched}")
            
            return self.merged_results
            
        except Exception as e:
            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø·Ø£
            if self.use_advanced_features and self.logger and AUDIT_LOGGER_AVAILABLE:
                try:
                    self.logger.log_error(
                        error_type=type(e).__name__,
                        error_message=str(e),
                        context={
                            'function': 'match_with_bank',
                            'time_window_days': time_window_days,
                            'use_record_linkage': use_record_linkage
                        }
                    )
                except:
                    pass
            
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©: {str(e)}")
            raise
    
    def _basic_matching(self, time_window_days: int) -> pd.DataFrame:
        """
        Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Exact + Fuzzy ÙÙ‚Ø·)
        Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ØªØªÙˆÙØ± Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        """
        results = []
        
        for idx, award_row in self.awards_data.iterrows():
            result = {
                'OwnerName': award_row.get('OwnerName', ''),
                'Race': award_row.get('Race', ''),
                'Season': award_row.get('Season', ''),
                'AwardAmount': award_row.get('AwardAmount', 0),
                'EntryDate': award_row.get('EntryDate', None),
                'BankDate': None,
                'BankReference': None,
                'MatchScore': 0,
                'StatusFlag': '',
                'ReasonText': '',
                'MatchType': 'No Match'
            }
            
            owner_name = award_row.get('OwnerName_norm', '')
            award_amount = award_row.get('AwardAmount', 0)
            entry_date = award_row.get('EntryDate', None)
            
            if pd.isna(award_amount) or pd.isna(entry_date):
                result['StatusFlag'] = 'âš ï¸'
                result['ReasonText'] = 'Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ø§Ù‚ØµØ©'
                results.append(result)
                continue
            
    def _basic_matching(self, time_window_days: int) -> pd.DataFrame:
        """
        Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø© (Reference-based + Fuzzy fallback)
        ØªØ³ØªØ®Ø¯Ù… merge Ø¹Ù„Ù‰ Reference Number Ù„Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù„ÙŠ
        """
        print(f"   ğŸš€ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ù…Ø­Ø³Ù‘Ù†Ø© (reference-based matching)")
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        awards_clean = self.awards_data[
            self.awards_data['AwardAmount'].notna() & 
            self.awards_data['EntryDate'].notna()
        ].copy()
        
        bank_clean = self.bank_data[
            self.bank_data['BankAmount'].notna() & 
            self.bank_data['BankDate'].notna()
        ].copy()
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¤Ø´Ø± Ù„Ù„Ø¬ÙˆØ§Ø¦Ø² Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªØ±ØªÙŠØ¨
        awards_clean['_award_idx'] = range(len(awards_clean))
        bank_clean['_bank_idx'] = range(len(bank_clean))
        
        # Ø§Ù„Ø·Ø¨Ù‚Ø© 1: Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¨ÙˆØ§Ø³Ø·Ø© Reference Number
        print(f"   ğŸ”‘ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¨ÙˆØ§Ø³Ø·Ø© Reference Number...")
        matched_results = []
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø¹Ù…ÙˆØ¯ Reference ÙÙŠ Ø§Ù„Ø¬ÙˆØ§Ø¦Ø²
        if 'paymentreference' in awards_clean.columns:
            awards_clean['AwardRef'] = awards_clean['paymentreference'].astype(str).str.strip()
        else:
            awards_clean['AwardRef'] = ''
        
        # ØªØµÙÙŠØ© Ø§Ù„Ø¬ÙˆØ§Ø¦Ø² Ø§Ù„ØªÙŠ Ù„Ù‡Ø§ reference ÙÙ‚Ø·
        awards_with_ref = awards_clean[
            awards_clean['AwardRef'].notna() & 
            (awards_clean['AwardRef'] != '') & 
            (awards_clean['AwardRef'] != 'nan')
        ].copy()
        
        print(f"      ğŸ“‹ {len(awards_with_ref):,} Ø¬Ø§Ø¦Ø²Ø© Ù„Ø¯ÙŠÙ‡Ø§ Reference Number")
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¹ AwardReferenceLong Ø£ÙˆÙ„Ø§Ù‹ (Ø£Ø¹Ù„Ù‰ Ù†Ø³Ø¨Ø© ØªØ·Ø§Ø¨Ù‚)
        if len(awards_with_ref) > 0 and 'AwardReferenceLong' in bank_clean.columns:
            bank_clean['BankRef'] = bank_clean['AwardReferenceLong'].astype(str).str.strip()
            
            # ØªØµÙÙŠØ© Ø§Ù„Ø¨Ù†Ùƒ Ù„Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªÙŠ Ù„Ù‡Ø§ reference ÙÙ‚Ø·
            bank_with_ref = bank_clean[
                bank_clean['BankRef'].notna() & 
                (bank_clean['BankRef'] != '') & 
                (bank_clean['BankRef'] != 'nan')
            ].copy()
            
            print(f"      ğŸ“‹ {len(bank_with_ref):,} Ù…Ø¹Ø§Ù…Ù„Ø© Ø¨Ù†ÙƒÙŠØ© Ù„Ø¯ÙŠÙ‡Ø§ AwardReferenceLong")
            
            # Ø¥ÙŠØ¬Ø§Ø¯ References Ø§Ù„Ù…Ø´ØªØ±ÙƒØ© ÙÙ‚Ø·
            common_refs = set(awards_with_ref['AwardRef'].unique()).intersection(
                set(bank_with_ref['BankRef'].unique())
            )
            
            print(f"      ğŸ”— {len(common_refs):,} Reference Ù…Ø´ØªØ±Ùƒ Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙÙŠÙ†")
            
            if len(common_refs) > 0:
                # ØªØµÙÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù€ references Ø§Ù„Ù…Ø´ØªØ±ÙƒØ© ÙÙ‚Ø·
                awards_filtered = awards_with_ref[awards_with_ref['AwardRef'].isin(common_refs)]
                bank_filtered = bank_with_ref[bank_with_ref['BankRef'].isin(common_refs)]
                
                ref_merge = pd.merge(
                    awards_filtered,
                    bank_filtered,
                    left_on='AwardRef',
                    right_on='BankRef',
                    how='inner',
                    suffixes=('', '_bank')
                )
            
            if len(ref_merge) > 0:
                # ØªØµÙÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ù†Ø§ÙØ°Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©
                ref_merge['_date_diff'] = (ref_merge['EntryDate'] - ref_merge['BankDate']).dt.days.abs()
                ref_merge = ref_merge[ref_merge['_date_diff'] <= time_window_days]
                
                if len(ref_merge) > 0:
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù…Ø¨Ù„Øº
                    ref_merge['_amount_diff'] = (ref_merge['AwardAmount'] - ref_merge['BankAmount']).abs()
                    ref_merge['_amount_match'] = ref_merge['_amount_diff'] < 0.01
                    
                    ref_merge['MatchType'] = ref_merge['_amount_match'].apply(
                        lambda x: 'Reference-Exact' if x else 'Reference-Diff'
                    )
                    ref_merge['MatchScore'] = ref_merge.apply(
                        lambda row: 100 if row['_amount_match'] else 95, axis=1
                    )
                    ref_merge['StatusFlag'] = ref_merge['_amount_match'].apply(
                        lambda x: 'âœ…' if x else 'âš ï¸'
                    )
                    ref_merge['ReasonText'] = ref_merge.apply(
                        lambda row: 'Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¨ÙˆØ§Ø³Ø·Ø© Reference (AwardReferenceLong)' if row['_amount_match']
                        else f'Ù…Ø·Ø§Ø¨Ù‚Ø© Reference Ù„ÙƒÙ† Ø§Ù„Ù…Ø¨Ù„Øº Ù…Ø®ØªÙ„Ù Ø¨Ù€ {row["_amount_diff"]:.2f}',
                        axis=1
                    )
                    matched_results.append(ref_merge)
                    print(f"      âœ“ {len(ref_merge):,} Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¹Ø¨Ø± AwardReferenceLong")
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¹ AwardReference Ù„Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©
        matched_award_idx = set()
        if matched_results:
            for df in matched_results:
                matched_award_idx.update(df['_award_idx'].tolist())
        
        unmatched_awards = awards_clean[~awards_clean['_award_idx'].isin(matched_award_idx)].copy()
        
        # ØªØµÙÙŠØ© Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªÙŠ Ù„Ù‡Ø§ reference
        unmatched_with_ref = unmatched_awards[
            unmatched_awards['AwardRef'].notna() & 
            (unmatched_awards['AwardRef'] != '') & 
            (unmatched_awards['AwardRef'] != 'nan')
        ].copy()
        
        if len(unmatched_with_ref) > 0 and 'AwardReference' in bank_clean.columns:
            bank_clean['BankRef2'] = bank_clean['AwardReference'].astype(str).str.strip()
            
            bank_with_ref2 = bank_clean[
                bank_clean['BankRef2'].notna() & 
                (bank_clean['BankRef2'] != '') & 
                (bank_clean['BankRef2'] != 'nan')
            ].copy()
            
            # Ø¥ÙŠØ¬Ø§Ø¯ References Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©
            common_refs2 = set(unmatched_with_ref['AwardRef'].unique()).intersection(
                set(bank_with_ref2['BankRef2'].unique())
            )
            
            if len(common_refs2) > 0:
                print(f"      ğŸ”— {len(common_refs2):,} Reference Ù…Ø´ØªØ±Ùƒ Ø¥Ø¶Ø§ÙÙŠ ÙÙŠ AwardReference")
                
                awards_filtered2 = unmatched_with_ref[unmatched_with_ref['AwardRef'].isin(common_refs2)]
                bank_filtered2 = bank_with_ref2[bank_with_ref2['BankRef2'].isin(common_refs2)]
                
                ref_merge2 = pd.merge(
                    awards_filtered2,
                    bank_filtered2,
                    left_on='AwardRef',
                    right_on='BankRef2',
                    how='inner',
                    suffixes=('', '_bank')
                )
            
            if len(ref_merge2) > 0:
                ref_merge2['_date_diff'] = (ref_merge2['EntryDate'] - ref_merge2['BankDate']).dt.days.abs()
                ref_merge2 = ref_merge2[ref_merge2['_date_diff'] <= time_window_days]
                
                if len(ref_merge2) > 0:
                    ref_merge2['MatchType'] = 'Reference'
                    ref_merge2['MatchScore'] = 100
                    ref_merge2['StatusFlag'] = 'âœ…'
                    ref_merge2['ReasonText'] = 'Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¨ÙˆØ§Ø³Ø·Ø© Reference (AwardReference)'
                    matched_results.append(ref_merge2)
                    print(f"      âœ“ {len(ref_merge2):,} Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¹Ø¨Ø± AwardReference")
        
        # Ø§Ù„Ø·Ø¨Ù‚Ø© 2: Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¶Ø¨Ø§Ø¨ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³Ù… ÙˆØ§Ù„Ù…Ø¨Ù„Øº (Ù„Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© ÙÙ‚Ø·)
        matched_award_idx = set()
        if matched_results:
            for df in matched_results:
                matched_award_idx.update(df['_award_idx'].tolist())
        
        unmatched_awards = awards_clean[~awards_clean['_award_idx'].isin(matched_award_idx)].copy()
        
        fuzzy_matches = []
        if len(unmatched_awards) > 0:
            # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù„Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø¶Ø¨Ø§Ø¨ÙŠØ©
            max_fuzzy = min(len(unmatched_awards), 5000)  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 5000 Ù„ØªØ¬Ù†Ø¨ Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            
            if len(unmatched_awards) > max_fuzzy:
                print(f"   âš ï¸ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø¶Ø¨Ø§Ø¨ÙŠØ© Ù„Ù€ {max_fuzzy:,} Ø¬Ø§Ø¦Ø²Ø© ÙÙ‚Ø· (Ù…Ù† {len(unmatched_awards):,})")
                # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙˆÙ„ 5000 Ø³Ø¬Ù„
                unmatched_for_fuzzy = unmatched_awards.head(max_fuzzy)
            else:
                unmatched_for_fuzzy = unmatched_awards
            
            print(f"   ğŸ” Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¶Ø¨Ø§Ø¨ÙŠØ© Ù„Ù€ {len(unmatched_for_fuzzy):,} Ø¬Ø§Ø¦Ø²Ø© Ù…ØªØ¨Ù‚ÙŠØ©...")
            
            for idx, award_row in unmatched_for_fuzzy.iterrows():
                award_amount = award_row['AwardAmount']
                award_date = award_row['EntryDate']
                award_name_norm = award_row.get('OwnerName_norm', '')
                
                # ØªØµÙÙŠØ© Ø§Ù„Ø¨Ù†Ùƒ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¨Ù„Øº ÙˆØ§Ù„ØªØ§Ø±ÙŠØ®
                date_min = award_date - pd.Timedelta(days=time_window_days)
                date_max = award_date + pd.Timedelta(days=time_window_days)
                
                candidate_bank = bank_clean[
                    (bank_clean['BankAmount'] == award_amount) &
                    (bank_clean['BankDate'] >= date_min) &
                    (bank_clean['BankDate'] <= date_max)
                ]
                
                if len(candidate_bank) == 0:
                    continue
                
                # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¶Ø¨Ø§Ø¨ÙŠØ©
                best_score = 0
                best_bank_row = None
                
                for _, bank_row in candidate_bank.iterrows():
                    bank_name_norm = bank_row.get('BankName_norm', '')
                    if bank_name_norm:
                        score = fuzz.ratio(award_name_norm, bank_name_norm)
                        
                        if score >= 85 and score > best_score:
                            best_score = score
                            best_bank_row = bank_row
                
                if best_bank_row is not None:
                    fuzzy_match = award_row.to_dict()
                    fuzzy_match.update({
                        'BankDate': best_bank_row['BankDate'],
                        'BankName': best_bank_row.get('BankName', ''),
                        'BankAmount': best_bank_row['BankAmount'],
                        'BankReference': best_bank_row.get('BankReference', ''),
                        'MatchType': 'Fuzzy',
                        'MatchScore': best_score,
                        'StatusFlag': 'âœ…',
                        'ReasonText': f'Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¶Ø¨Ø§Ø¨ÙŠØ© Ø¨Ø§Ù„Ø§Ø³Ù… {best_score}%'
                    })
                    fuzzy_matches.append(fuzzy_match)
                
                # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªÙ‚Ø¯Ù… ÙƒÙ„ 500 Ø³Ø¬Ù„
                if (len(fuzzy_matches) + 1) % 500 == 0:
                    print(f"      Ù…Ø¹Ø§Ù„Ø¬Ø©: {len(fuzzy_matches):,} Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¶Ø¨Ø§Ø¨ÙŠØ©...")
            
            if len(fuzzy_matches) > 0:
                print(f"      âœ“ {len(fuzzy_matches):,} Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¶Ø¨Ø§Ø¨ÙŠØ©")
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        results_list = []
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Ø¨Ø§Ù„Ù€ Reference
        for ref_match in matched_results:
            ref_results = ref_match[[
                'OwnerName', 'Race', 'Season', 'AwardAmount', 'EntryDate',
                'BankDate', 'BankName', 'BankAmount', 'BankReference',
                'MatchType', 'MatchScore', 'StatusFlag', 'ReasonText', '_award_idx'
            ]].copy()
            # Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ AwardRef Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
            if 'AwardRef' in ref_match.columns:
                ref_results['AwardRef'] = ref_match['AwardRef']
            results_list.append(ref_results)
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Ø§Ù„Ø¶Ø¨Ø§Ø¨ÙŠØ©
        if fuzzy_matches:
            fuzzy_df = pd.DataFrame(fuzzy_matches)
            fuzzy_results = fuzzy_df[[
                'OwnerName', 'Race', 'Season', 'AwardAmount', 'EntryDate',
                'BankDate', 'BankName', 'BankAmount', 'BankReference',
                'MatchType', 'MatchScore', 'StatusFlag', 'ReasonText', '_award_idx'
            ]].copy()
            # Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ AwardRef Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
            if 'AwardRef' in fuzzy_df.columns:
                fuzzy_results['AwardRef'] = fuzzy_df['AwardRef']
            results_list.append(fuzzy_results)
        
        # ØªØ­Ø¯ÙŠØ« Ù…Ø¤Ø´Ø± Ø§Ù„Ø¬ÙˆØ§Ø¦Ø² Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
        matched_award_idx = set()
        for df in results_list:
            matched_award_idx.update(df['_award_idx'].tolist())
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¬ÙˆØ§Ø¦Ø² ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
        final_unmatched = awards_clean[~awards_clean['_award_idx'].isin(matched_award_idx)].copy()
        if len(final_unmatched) > 0:
            final_unmatched['BankDate'] = pd.NaT
            final_unmatched['BankName'] = ''
            final_unmatched['BankAmount'] = np.nan
            final_unmatched['BankReference'] = ''
            final_unmatched['MatchType'] = 'No Match'
            final_unmatched['MatchScore'] = 0
            final_unmatched['StatusFlag'] = 'âš ï¸'
            final_unmatched['ReasonText'] = 'Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø·Ø§Ø¨Ù‚Ø© ÙÙŠ ÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ'
            
            unmatched_results = final_unmatched[[
                'OwnerName', 'Race', 'Season', 'AwardAmount', 'EntryDate',
                'BankDate', 'BankName', 'BankAmount', 'BankReference',
                'MatchType', 'MatchScore', 'StatusFlag', 'ReasonText', '_award_idx'
            ]].copy()
            results_list.append(unmatched_results)
        
        # Ø¯Ù…Ø¬ ÙƒÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        if results_list:
            final_results = pd.concat(results_list, ignore_index=True)
            final_results = final_results.sort_values('_award_idx').drop(columns=['_award_idx'])
        else:
            final_results = pd.DataFrame(columns=[
                'OwnerName', 'Race', 'Season', 'AwardAmount', 'EntryDate',
                'BankDate', 'BankName', 'BankAmount', 'BankReference',
                'MatchType', 'MatchScore', 'StatusFlag', 'ReasonText'
            ])
        
        return final_results
    
    def detect_internal_duplicates(self) -> pd.DataFrame:
        """
        ÙƒØ´Ù Ø§Ù„ØµØ±Ù Ø§Ù„Ù…ÙƒØ±Ø± Ø¯Ø§Ø®Ù„ Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬ÙˆØ§Ø¦Ø²
        
        Returns:
            DataFrame Ø¨Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©
        """
        if self.merged_results is None:
            raise ValueError("ÙŠØ¬Ø¨ Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¹ Ø§Ù„Ø¨Ù†Ùƒ Ø£ÙˆÙ„Ø§Ù‹")
        
        df = self.merged_results.copy()
        
        # ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨: Ø§Ù„Ø§Ø³Ù…ØŒ Ø§Ù„Ø³Ø¨Ø§Ù‚ØŒ Ø§Ù„Ù…Ø¨Ù„Øº
        grouped = df.groupby(['OwnerName', 'Race', 'AwardAmount'])
        
        for name, group in grouped:
            if len(group) > 1:
                # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
                dates = group['EntryDate'].dropna().unique()
                
                if len(dates) > 1:
                    # ØªÙƒØ±Ø§Ø± Ù…Ø´ØªØ¨Ù‡ - Ù†ÙØ³ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨ØªÙˆØ§Ø±ÙŠØ® Ù…Ø®ØªÙ„ÙØ©
                    indices = group.index
                    df.loc[indices, 'StatusFlag'] = 'âš ï¸'
                    df.loc[indices, 'ReasonText'] = df.loc[indices, 'ReasonText'] + ' | ØµØ±Ù Ù…ÙƒØ±Ø± Ù…Ø´ØªØ¨Ù‡'
        
        # ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙƒØ±Ø§Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ Ø§Ù„Ø¨Ù†ÙƒÙŠ
        if 'BankReference' in df.columns:
            bank_refs = df['BankReference'].dropna()
            duplicate_refs = bank_refs[bank_refs.duplicated(keep=False)]
            
            if len(duplicate_refs) > 0:
                for ref in duplicate_refs.unique():
                    indices = df[df['BankReference'] == ref].index
                    df.loc[indices, 'StatusFlag'] = 'âŒ'
                    df.loc[indices, 'ReasonText'] = df.loc[indices, 'ReasonText'] + ' | ØµØ±Ù Ù…ÙƒØ±Ø± Ù…Ø¤ÙƒØ¯ (Ù…Ø±Ø¬Ø¹ Ø¨Ù†ÙƒÙŠ Ù…ÙƒØ±Ø±)'
        
        self.merged_results = df
        return df
    
    def calculate_statistics(self) -> Dict[str, Any]:
        """
        Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©
        
        Returns:
            Ù‚Ø§Ù…ÙˆØ³ Ø¨Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        """
        if self.merged_results is None:
            return {}
        
        df = self.merged_results
        
        total_records = len(df)
        matched_ok = len(df[df['StatusFlag'] == 'âœ…'])
        suspected = len(df[df['StatusFlag'] == 'âš ï¸'])
        confirmed_duplicate = len(df[df['StatusFlag'] == 'âŒ'])
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…ÙˆØ³Ù…
        seasons_stats = {}
        if 'Season' in df.columns:
            seasons_stats = df.groupby('Season').size().to_dict()
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ø³Ø¨Ø§Ù‚
        races_stats = {}
        if 'Race' in df.columns:
            races_stats = df.groupby('Race').size().to_dict()
        
        self.statistics = {
            'total_records': total_records,
            'matched_ok': matched_ok,
            'suspected': suspected,
            'confirmed_duplicate': confirmed_duplicate,
            'match_rate': (matched_ok / total_records * 100) if total_records > 0 else 0,
            'seasons': seasons_stats,
            'races': races_stats,
            'total_amount': df['AwardAmount'].sum() if 'AwardAmount' in df.columns else 0
        }
        
        return self.statistics
    
    def export_report(self, output_path: str = None) -> str:
        """
        ØªØµØ¯ÙŠØ± Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¥Ù„Ù‰ Excel (Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…ØªÙ‚Ø¯Ù… v2.0)
        
        Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©:
        - Sheet 1: Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„Ø©
        - Sheet 2: Ø¬Ø¯ÙˆÙ„ Pivot ØªÙØ§Ø¹Ù„ÙŠ
        - Sheet 3: Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©
        - Sheet 4: Audit Log (Ø³Ø¬Ù„ Ø§Ù„ØªØ´ØºÙŠÙ„)
        
        Args:
            output_path: Ù…Ø³Ø§Ø± Ø§Ù„Ø­ÙØ¸
            
        Returns:
            Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­ÙÙˆØ¸
        """
        if self.merged_results is None:
            raise ValueError("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù„Ù„ØªØµØ¯ÙŠØ±")
        
        if output_path is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_path = f'outputs/camel_awards_report_{timestamp}.xlsx'
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        
        print(f"\nğŸ“Š ØªØµØ¯ÙŠØ± Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…...")
        
        try:
            with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:
                workbook = writer.book
                
                # ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø§Ù„Ø£Ù„ÙˆØ§Ù†
                green_format = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100'})
                yellow_format = workbook.add_format({'bg_color': '#FFEB9C', 'font_color': '#9C6500'})
                red_format = workbook.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006'})
                header_format = workbook.add_format({
                    'bold': True,
                    'bg_color': '#4472C4',
                    'font_color': 'white',
                    'align': 'center'
                })
                
                # Sheet 1: Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                self.merged_results.to_excel(writer, sheet_name='Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„Ø©', index=False)
                worksheet = writer.sheets['Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„Ø©']
                
                # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø´Ø±Ø·ÙŠ
                if 'StatusFlag' in self.merged_results.columns:
                    status_col = self.merged_results.columns.get_loc('StatusFlag')
                    for row_num, status in enumerate(self.merged_results['StatusFlag'], start=1):
                        if status == 'âœ…':
                            worksheet.write(row_num, status_col, status, green_format)
                        elif status == 'âš ï¸':
                            worksheet.write(row_num, status_col, status, yellow_format)
                        elif status == 'âŒ':
                            worksheet.write(row_num, status_col, status, red_format)
                
                print(f"   âœ… Sheet 1: Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„Ø© ({len(self.merged_results):,} Ø³Ø¬Ù„)")
                
                # Sheet 2: Ù…Ù„Ø®Øµ Pivot
                if 'Season' in self.merged_results.columns and 'Race' in self.merged_results.columns:
                    try:
                        pivot = pd.pivot_table(
                            self.merged_results,
                            values='AwardAmount',
                            index=['Season', 'Race'],
                            columns='StatusFlag',
                            aggfunc='count',
                            fill_value=0
                        )
                        pivot.to_excel(writer, sheet_name='Ù…Ù„Ø®Øµ Pivot')
                        print(f"   âœ… Sheet 2: Ø¬Ø¯ÙˆÙ„ Pivot")
                    except Exception as e:
                        print(f"   âš ï¸ ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Pivot - {str(e)}")
                
                # Sheet 3: Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                if self.statistics:
                    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¥Ù„Ù‰ DataFrame Ø£ÙƒØ«Ø± ÙˆØ¶ÙˆØ­Ø§Ù‹
                    stats_rows = []
                    for key, value in self.statistics.items():
                        if not isinstance(value, dict):
                            stats_rows.append({
                                'Ø§Ù„Ù…Ø¤Ø´Ø±': key,
                                'Ø§Ù„Ù‚ÙŠÙ…Ø©': value
                            })
                    
                    stats_df = pd.DataFrame(stats_rows)
                    stats_df.to_excel(writer, sheet_name='Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª', index=False)
                    
                    # ØªÙ†Ø³ÙŠÙ‚ Ø±Ø£Ø³ Ø§Ù„Ø¬Ø¯ÙˆÙ„
                    worksheet_stats = writer.sheets['Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª']
                    for col_num, value in enumerate(stats_df.columns.values):
                        worksheet_stats.write(0, col_num, value, header_format)
                    
                    print(f"   âœ… Sheet 3: Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ({len(stats_rows)} Ù…Ø¤Ø´Ø±)")
                
                # Sheet 4: Audit Log (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹)
                if self.use_advanced_features and self.logger and AUDIT_LOGGER_AVAILABLE and self.current_run_id:
                    try:
                        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªØ´ØºÙŠÙ„
                        run_details = self.logger.get_run_details(self.current_run_id)
                        run_info = run_details.get('run_info', {})
                        
                        if run_info:
                            audit_rows = [
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'RunID', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': self.current_run_id},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ´ØºÙŠÙ„', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': run_info.get('Timestamp', 'N/A')},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¬ÙˆØ§Ø¦Ø²', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': run_info.get('TotalAwards', 0)},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Exact', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': run_info.get('ExactMatches', 0)},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Fuzzy', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': run_info.get('FuzzyMatches', 0)},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'Ù…Ø·Ø§Ø¨Ù‚Ø§Øª RL', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': run_info.get('RLMatches', 0)},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': run_info.get('UnmatchedAwards', 0)},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ° (Ø«)', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': f"{run_info.get('ExecutionTimeSeconds', 0):.2f}"},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': run_info.get('UserName', 'System')},
                                {'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©': 'Ø§Ù„Ø­Ø§Ù„Ø©', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': run_info.get('Status', 'N/A')}
                            ]
                            
                            audit_df = pd.DataFrame(audit_rows)
                            audit_df.to_excel(writer, sheet_name='Audit Log', index=False)
                            
                            # ØªÙ†Ø³ÙŠÙ‚ Ø±Ø£Ø³ Ø§Ù„Ø¬Ø¯ÙˆÙ„
                            worksheet_audit = writer.sheets['Audit Log']
                            for col_num, value in enumerate(audit_df.columns.values):
                                worksheet_audit.write(0, col_num, value, header_format)
                            
                            print(f"   âœ… Sheet 4: Audit Log (RunID: {self.current_run_id[:8]}...)")
                    
                    except Exception as e:
                        print(f"   âš ï¸ ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø¥Ø¶Ø§ÙØ© Audit Log - {str(e)}")
            
            print(f"\nâœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØµØ¯ÙŠØ±: {str(e)}")
            raise
    
    def filter_results(
        self, 
        season: Optional[str] = None,
        race: Optional[str] = None,
        status: Optional[str] = None,
        participant: Optional[str] = None
    ) -> pd.DataFrame:
        """
        ÙÙ„ØªØ±Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        
        Args:
            season: Ø§Ù„Ù…ÙˆØ³Ù…
            race: Ø§Ù„Ø³Ø¨Ø§Ù‚
            status: Ø§Ù„Ø­Ø§Ù„Ø©
            participant: Ø§Ù„Ù…Ø´Ø§Ø±Ùƒ
            
        Returns:
            DataFrame Ù…ÙÙ„ØªØ±
        """
        if self.merged_results is None:
            return pd.DataFrame()
        
        df = self.merged_results.copy()
        
        if season and 'Season' in df.columns:
            df = df[df['Season'] == season]
        
        if race and 'Race' in df.columns:
            df = df[df['Race'] == race]
        
        if status and 'StatusFlag' in df.columns:
            df = df[df['StatusFlag'] == status]
        
        if participant and 'OwnerName' in df.columns:
            df = df[df['OwnerName'].str.contains(participant, case=False, na=False)]
        
        return df
