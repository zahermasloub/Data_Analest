# -*- coding: utf-8 -*-
"""
âš¡ Ù…ÙØ­Ø³ÙÙ‘Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡ - Performance Optimizer
==========================================
ØªØ³Ø±ÙŠØ¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… DuckDB Ùˆ Dask

Libraries Used:
- duckdb>=0.9.0 (Ù„Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª SQL Ø§Ù„Ø³Ø±ÙŠØ¹Ø©)
- dask[complete]>=2023.12.0 (Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ÙˆØ²Ø¹Ø©)
- pandas>=2.1.0
- pyarrow>=14.0.0

Install if missing:
pip install duckdb "dask[complete]" pandas pyarrow
"""

import pandas as pd
from pathlib import Path
from typing import List, Dict, Optional, Union
import warnings

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ duckdb
try:
    import duckdb
    DUCKDB_AVAILABLE = True
except ImportError:
    DUCKDB_AVAILABLE = False
    warnings.warn("âš ï¸ duckdb ØºÙŠØ± Ù…ØªÙˆÙØ± - Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… pandas Ø§Ù„Ø¹Ø§Ø¯ÙŠ")

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ dask
try:
    import dask.dataframe as dd
    from dask.diagnostics import ProgressBar
    DASK_AVAILABLE = True
except ImportError:
    DASK_AVAILABLE = False
    warnings.warn("âš ï¸ dask ØºÙŠØ± Ù…ØªÙˆÙØ± - Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… pandas Ø§Ù„Ø¹Ø§Ø¯ÙŠ")


class PerformanceOptimizer:
    """Ù…Ø­Ø³ÙÙ‘Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©"""
    
    def __init__(self, use_duckdb: bool = True, use_dask: bool = False):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ø³ÙÙ‘Ù†
        
        Args:
            use_duckdb: Ø§Ø³ØªØ®Ø¯Ø§Ù… DuckDB Ù„Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø³Ø±ÙŠØ¹Ø©
            use_dask: Ø§Ø³ØªØ®Ø¯Ø§Ù… Dask Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ÙˆØ²Ø¹Ø©
        """
        self.use_duckdb = use_duckdb and DUCKDB_AVAILABLE
        self.use_dask = use_dask and DASK_AVAILABLE
        self.conn = None
        
        if self.use_duckdb:
            self._init_duckdb()
    
    def _init_duckdb(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§ØªØµØ§Ù„ DuckDB ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        try:
            self.conn = duckdb.connect(':memory:')
            print("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© DuckDB ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©")
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© DuckDB: {str(e)}")
            self.use_duckdb = False
    
    def load_excel_optimized(
        self,
        file_path: Union[str, Path],
        sheet_name: Optional[str] = None
    ) -> pd.DataFrame:
        """
        ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Excel Ø¨Ø£Ø¯Ø§Ø¡ Ù…Ø­Ø³Ù‘Ù†
        
        Library Used: pandas, dask (optional)
        
        Args:
            file_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù
            sheet_name: Ø§Ø³Ù… Ø§Ù„ÙˆØ±Ù‚Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            
        Returns:
            DataFrame
        """
        file_path = Path(file_path)
        
        if not file_path.exists():
            raise FileNotFoundError(f"Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {file_path}")
        
        print(f"ğŸ“‚ ØªØ­Ù…ÙŠÙ„: {file_path.name}")
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… pandas Ø§Ù„Ø¹Ø§Ø¯ÙŠ (Ø£Ø³Ø±Ø¹ Ù„Ù…Ù„ÙØ§Øª Excel)
        try:
            df = pd.read_excel(
                file_path,
                sheet_name=sheet_name or 0,
                engine='openpyxl'
            )
            print(f"   âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df):,} ØµÙ")
            return df
        except Exception as e:
            print(f"   âŒ Ø®Ø·Ø£: {str(e)}")
            return pd.DataFrame()
    
    def load_multiple_excel_optimized(
        self,
        file_paths: List[Union[str, Path]],
        sheet_name: Optional[str] = None
    ) -> pd.DataFrame:
        """
        ØªØ­Ù…ÙŠÙ„ ÙˆØ¯Ù…Ø¬ Ø¹Ø¯Ø© Ù…Ù„ÙØ§Øª Excel
        
        Library Used: pandas, dask (optional)
        
        Args:
            file_paths: Ù‚Ø§Ø¦Ù…Ø© Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª
            sheet_name: Ø§Ø³Ù… Ø§Ù„ÙˆØ±Ù‚Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            
        Returns:
            DataFrame Ù…Ø¯Ù…Ø¬
        """
        if not file_paths:
            return pd.DataFrame()
        
        print(f"ğŸ“‚ ØªØ­Ù…ÙŠÙ„ {len(file_paths)} Ù…Ù„Ù...")
        
        dataframes = []
        for file_path in file_paths:
            df = self.load_excel_optimized(file_path, sheet_name)
            if not df.empty:
                dataframes.append(df)
        
        if not dataframes:
            return pd.DataFrame()
        
        # Ø§Ù„Ø¯Ù…Ø¬
        print("ğŸ”„ Ø¯Ù…Ø¬ Ø§Ù„Ù…Ù„ÙØ§Øª...")
        combined = pd.concat(dataframes, ignore_index=True)
        print(f"   âœ… Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {len(combined):,} ØµÙ")
        
        return combined
    
    def filter_by_amount_duckdb(
        self,
        df: pd.DataFrame,
        min_amount: Optional[float] = None,
        max_amount: Optional[float] = None,
        amount_column: str = 'AwardAmount'
    ) -> pd.DataFrame:
        """
        ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¨Ù„Øº Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… DuckDB
        
        Library Used: duckdb
        
        Args:
            df: DataFrame
            min_amount: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰
            max_amount: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰
            amount_column: Ø§Ø³Ù… Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø¨Ù„Øº
            
        Returns:
            DataFrame Ù…ÙÙ„ØªØ±
        """
        if not self.use_duckdb or df.empty:
            # Fallback Ø¥Ù„Ù‰ pandas
            result = df.copy()
            if min_amount is not None:
                result = result[result[amount_column] >= min_amount]
            if max_amount is not None:
                result = result[result[amount_column] <= max_amount]
            return result
        
        try:
            # Ø§Ø³ØªØ¹Ù„Ø§Ù… DuckDB
            query = f"SELECT * FROM df WHERE 1=1"
            
            if min_amount is not None:
                query += f" AND {amount_column} >= {min_amount}"
            
            if max_amount is not None:
                query += f" AND {amount_column} <= {max_amount}"
            
            result = self.conn.execute(query).df()
            return result
            
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ DuckDB: {str(e)}")
            # Fallback
            result = df.copy()
            if min_amount is not None:
                result = result[result[amount_column] >= min_amount]
            if max_amount is not None:
                result = result[result[amount_column] <= max_amount]
            return result
    
    def join_dataframes_duckdb(
        self,
        left_df: pd.DataFrame,
        right_df: pd.DataFrame,
        left_on: str,
        right_on: str,
        how: str = 'inner'
    ) -> pd.DataFrame:
        """
        Ø¯Ù…Ø¬ DataFrames Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… DuckDB
        
        Library Used: duckdb
        
        Args:
            left_df: Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£ÙŠØ³Ø±
            right_df: Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£ÙŠÙ…Ù†
            left_on: Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© (Ø£ÙŠØ³Ø±)
            right_on: Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© (Ø£ÙŠÙ…Ù†)
            how: Ù†ÙˆØ¹ Ø§Ù„Ø¯Ù…Ø¬ (inner/left/right/outer)
            
        Returns:
            DataFrame Ù…Ø¯Ù…Ø¬
        """
        if not self.use_duckdb:
            # Fallback Ø¥Ù„Ù‰ pandas
            return pd.merge(
                left_df,
                right_df,
                left_on=left_on,
                right_on=right_on,
                how=how
            )
        
        try:
            # Ø§Ø³ØªØ¹Ù„Ø§Ù… DuckDB
            join_type = how.upper()
            
            query = f"""
                SELECT *
                FROM left_df
                {join_type} JOIN right_df
                ON left_df.{left_on} = right_df.{right_on}
            """
            
            result = self.conn.execute(query).df()
            return result
            
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ DuckDB: {str(e)}")
            # Fallback
            return pd.merge(
                left_df,
                right_df,
                left_on=left_on,
                right_on=right_on,
                how=how
            )
    
    def aggregate_by_group_duckdb(
        self,
        df: pd.DataFrame,
        group_by: List[str],
        agg_columns: Dict[str, str]
    ) -> pd.DataFrame:
        """
        ØªØ¬Ù…ÙŠØ¹ ÙˆØªÙ„Ø®ÙŠØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… DuckDB
        
        Library Used: duckdb
        
        Args:
            df: DataFrame
            group_by: Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªØ¬Ù…ÙŠØ¹
            agg_columns: Ù‚Ø§Ù…ÙˆØ³ {Ø¹Ù…ÙˆØ¯: Ø¯Ø§Ù„Ø©} Ù…Ø«Ù„ {'Amount': 'SUM'}
            
        Returns:
            DataFrame Ù…Ø¬Ù…ÙÙ‘Ø¹
        """
        if not self.use_duckdb or df.empty:
            # Fallback Ø¥Ù„Ù‰ pandas
            agg_dict = {col: func.lower() for col, func in agg_columns.items()}
            return df.groupby(group_by).agg(agg_dict).reset_index()
        
        try:
            # Ø¨Ù†Ø§Ø¡ Ø§Ø³ØªØ¹Ù„Ø§Ù… SQL
            select_parts = [', '.join(group_by)]
            
            for col, func in agg_columns.items():
                select_parts.append(f"{func}({col}) as {col}_{func}")
            
            select_clause = ', '.join(select_parts)
            group_clause = ', '.join(group_by)
            
            query = f"""
                SELECT {select_clause}
                FROM df
                GROUP BY {group_clause}
            """
            
            result = self.conn.execute(query).df()
            return result
            
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ DuckDB: {str(e)}")
            # Fallback
            agg_dict = {col: func.lower() for col, func in agg_columns.items()}
            return df.groupby(group_by).agg(agg_dict).reset_index()
    
    def process_large_file_dask(
        self,
        file_path: Union[str, Path],
        processing_func,
        chunk_size: str = '100MB'
    ) -> pd.DataFrame:
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù ÙƒØ¨ÙŠØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Dask
        
        Library Used: dask
        
        Args:
            file_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù
            processing_func: Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            chunk_size: Ø­Ø¬Ù… Ø§Ù„Ù‚Ø·Ø¹Ø©
            
        Returns:
            DataFrame Ù…Ø¹Ø§Ù„Ø¬
        """
        if not self.use_dask:
            # Fallback Ø¥Ù„Ù‰ pandas
            df = pd.read_csv(file_path)
            return processing_func(df)
        
        try:
            # Ù‚Ø±Ø§Ø¡Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Dask
            ddf = dd.read_csv(file_path, blocksize=chunk_size)
            
            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¯Ø§Ù„Ø©
            result_ddf = ddf.map_partitions(processing_func)
            
            # ØªÙ†ÙÙŠØ° Ù…Ø¹ Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
            with ProgressBar():
                result = result_ddf.compute()
            
            return result
            
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ Dask: {str(e)}")
            # Fallback
            df = pd.read_csv(file_path)
            return processing_func(df)
    
    def get_statistics(self) -> Dict[str, any]:
        """
        Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
        
        Returns:
            Ù‚Ø§Ù…ÙˆØ³ Ø¨Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        """
        return {
            'duckdb_enabled': self.use_duckdb,
            'dask_enabled': self.use_dask,
            'duckdb_available': DUCKDB_AVAILABLE,
            'dask_available': DASK_AVAILABLE
        }
    
    def close(self):
        """Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª"""
        if self.conn:
            try:
                self.conn.close()
                print("âœ… ØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ø§ØªØµØ§Ù„ DuckDB")
            except:
                pass
    
    def __del__(self):
        """Destructor"""
        self.close()


# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©
def recommend_optimizer_settings(file_size_mb: float) -> Dict[str, bool]:
    """
    ØªÙˆØµÙŠØ© Ø¨Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø­Ø³ÙÙ‘Ù† Ø­Ø³Ø¨ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù
    
    Args:
        file_size_mb: Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù (MB)
        
    Returns:
        Ù‚Ø§Ù…ÙˆØ³ Ø¨Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§
    """
    if file_size_mb < 10:
        # Ù…Ù„ÙØ§Øª ØµØºÙŠØ±Ø© - pandas Ø¹Ø§Ø¯ÙŠ
        return {
            'use_duckdb': False,
            'use_dask': False,
            'reason': 'Ù…Ù„Ù ØµØºÙŠØ± - pandas Ø¹Ø§Ø¯ÙŠ ÙƒØ§ÙÙ'
        }
    
    elif file_size_mb < 100:
        # Ù…Ù„ÙØ§Øª Ù…ØªÙˆØ³Ø·Ø© - DuckDB ÙÙ‚Ø·
        return {
            'use_duckdb': True,
            'use_dask': False,
            'reason': 'Ù…Ù„Ù Ù…ØªÙˆØ³Ø· - Ø§Ø³ØªØ®Ø¯Ø§Ù… DuckDB Ù„Ù„ØªØ³Ø±ÙŠØ¹'
        }
    
    else:
        # Ù…Ù„ÙØ§Øª ÙƒØ¨ÙŠØ±Ø© - DuckDB + Dask
        return {
            'use_duckdb': True,
            'use_dask': True,
            'reason': 'Ù…Ù„Ù ÙƒØ¨ÙŠØ± - Ø§Ø³ØªØ®Ø¯Ø§Ù… DuckDB + Dask'
        }
