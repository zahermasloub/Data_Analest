"""
ØªØ´ØºÙŠÙ„ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„ØµØ§Ø±Ù… - Ø¯Ù‚Ø© 100%
=====================================

Ù†Ø¸Ø§Ù… ØªØ¯Ù‚ÙŠÙ‚ Ù…ØªÙ‚Ø¯Ù… Ø¨Ù…Ø¹Ø§ÙŠÙŠØ± ØµØ§Ø±Ù…Ø© Ù„Ù„Ø¬Ù‡Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ©
"""

from pathlib import Path
import sys
import os

# Fix Windows console encoding
if sys.platform == 'win32':
    try:
        import codecs
        sys.stdout.reconfigure(encoding='utf-8')
    except:
        pass

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent))

from core.strict_audit_analyzer import StrictAuditAnalyzer
import pandas as pd


def main():
    print("="*80)
    print("ğŸ”’ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„ØµØ§Ø±Ù… - Ø¯Ù‚Ø© 100%")
    print("="*80)
    print("ğŸ“‹ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª:")
    print("   âœ“ ÙƒØ´Ù Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø¨Ø¯Ù‚Ø© 100%")
    print("   âœ“ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨Ù†Ùƒ Ø¨Ø¯Ù‚Ø© 100%")
    print("   âœ“ Ø¨Ø¯ÙˆÙ† ØªØ³Ø§Ù…Ø­ ÙÙŠ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡")
    print("   âœ“ ØªÙ‚Ø§Ø±ÙŠØ± Ù…Ø¹ØªÙ…Ø¯Ø© Ù„Ù„Ø¬Ù‡Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ©")
    print("="*80)
    
    # Initialize analyzer
    analyzer = StrictAuditAnalyzer()
    
    # Step 1: Load award files
    print("\nğŸ“‚ Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬ÙˆØ§Ø¦Ø²")
    print("-" * 80)
    
    # Use combined file
    awards_file = Path("uploads/Combined_Awards_2018_2025.xlsx")
    
    if not awards_file.exists():
        print(f"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {awards_file}")
        return
    
    try:
        print(f"   ğŸ“„ ØªØ­Ù…ÙŠÙ„: {awards_file.name}... ", end='')
        awards_data = pd.read_excel(awards_file)
        awards_data['SourceFile'] = awards_file.name
        print(f"âœ… ({len(awards_data):,} Ø³Ø¬Ù„)")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£: {e}")
        return
    
    print(f"\nâœ… Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª: {len(awards_data):,}")
    
    # Step 2: Detect duplicates with 100% accuracy
    print("\nğŸ” Ø§Ù„Ø®Ø·ÙˆØ© 2: ÙƒØ´Ù Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø¨Ù…Ø¹ÙŠØ§Ø± 100%")
    print("-" * 80)
    print("ğŸ“‹ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ù…Ø±ÙƒØ¨ (Composite Key):")
    print("   1. Season (Ø§Ù„Ù…ÙˆØ³Ù…)")
    print("   2. Race (Ø§Ù„Ø³Ø¨Ø§Ù‚)")
    print("   3. Owner Number (Ø±Ù‚Ù… Ø§Ù„Ù…Ø§Ù„Ùƒ)")
    print("   4. Owner Name (Ø§Ø³Ù… Ø§Ù„Ù…Ø§Ù„Ùƒ)")
    print("   5. Owner QatariID (Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ù‚Ø·Ø±ÙŠ)")
    print("   6. Award Amount (Ù…Ø¨Ù„Øº Ø§Ù„Ø¬Ø§Ø¦Ø²Ø©)")
    print("\nâš ï¸ Ù…Ù„Ø§Ø­Ø¸Ø©: Entry Date Ù…Ø³Ù…ÙˆØ­ Ø¨Ø§Ø®ØªÙ„Ø§ÙÙ‡ (Ù‡Ø°Ø§ Ù…Ø§ ÙŠÙƒØ´Ù Ø§Ù„ØªÙƒØ±Ø§Ø±)")
    
    duplicates = analyzer.detect_strict_duplicates(awards_data)
    
    # Step 3: Load bank statement
    print("\nğŸ¦ Ø§Ù„Ø®Ø·ÙˆØ© 3: ØªØ­Ù…ÙŠÙ„ ÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ")
    print("-" * 80)
    
    bank_file = Path("uploads/Ø§Ù„Ø¹Ø¬ÙˆØ±ÙŠ 11-4.csv")
    if bank_file.exists():
        try:
            print(f"   ğŸ“„ ØªØ­Ù…ÙŠÙ„: {bank_file.name}... ", end='')
            
            # Try to find header row
            df_peek = pd.read_csv(bank_file, nrows=20, encoding='utf-8-sig', encoding_errors='ignore')
            header_row = None
            
            for i in range(len(df_peek)):
                row_values = df_peek.iloc[i].astype(str).str.lower()
                if any('award' in str(v).lower() or 'reference' in str(v).lower() for v in row_values):
                    header_row = i
                    break
            
            if header_row is None:
                header_row = 0
            
            bank_data = pd.read_csv(bank_file, header=header_row, encoding='utf-8-sig', encoding_errors='ignore')
            
            # Normalize column names
            bank_data.columns = bank_data.columns.str.strip()
            
            # Map columns
            column_mapping = {}
            for col in bank_data.columns:
                col_lower = col.lower().strip()
                if 'award ref 10 digits' in col_lower or 'awardref10digits' in col_lower:
                    column_mapping[col] = 'AwardRef10Digits'
                elif 'award ref' in col_lower and '10' not in col_lower:
                    column_mapping[col] = 'AwardRef'
                elif 'bank reference' in col_lower or 'bankreference' in col_lower:
                    column_mapping[col] = 'BankReference'
                elif 'request reference' in col_lower:
                    column_mapping[col] = 'RequestReference'
                elif 'transaction date' in col_lower:
                    column_mapping[col] = 'TransactionDate'
                elif 'value date' in col_lower:
                    column_mapping[col] = 'ValueDate'
                elif 'beneficiary' in col_lower and 'name' in col_lower:
                    column_mapping[col] = 'BeneficiaryName'
                elif 'debit' in col_lower:
                    column_mapping[col] = 'Debit'
                elif 'credit' in col_lower:
                    column_mapping[col] = 'Credit'
                elif 'iban' in col_lower:
                    column_mapping[col] = 'IBAN'
            
            if column_mapping:
                bank_data = bank_data.rename(columns=column_mapping)
            
            # Calculate TransferAmount
            if 'Credit' in bank_data.columns:
                bank_data['TransferAmount'] = pd.to_numeric(bank_data['Credit'], errors='coerce')
            elif 'Debit' in bank_data.columns:
                bank_data['TransferAmount'] = pd.to_numeric(bank_data['Debit'], errors='coerce')
            
            print(f"âœ… ({len(bank_data):,} Ù…Ø¹Ø§Ù…Ù„Ø©)")
            print(f"   ğŸ“‹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
            key_cols = ['AwardRef', 'AwardRef10Digits', 'BankReference', 'TransferAmount']
            for col in key_cols:
                if col in bank_data.columns:
                    non_null = bank_data[col].notna().sum()
                    print(f"      â€¢ {col}: {non_null:,} Ù‚ÙŠÙ…Ø©")
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£: {e}")
            bank_data = None
    else:
        print(f"   âš ï¸ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {bank_file.name}")
        bank_data = None
    
    # Step 4: Verify against bank (100% accuracy)
    if len(duplicates) > 0 and bank_data is not None:
        print("\nâœ… Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ Ø¨Ù…Ø¹ÙŠØ§Ø± 100%")
        print("-" * 80)
        
        verification_results = analyzer.verify_bank_strict(duplicates, bank_data)
        
        # Store results
        analyzer.matched_df = verification_results['matched']
        analyzer.unmatched_df = verification_results['unmatched']
        
        # Update duplicates with confirmed status
        # Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ù…Ø¤ÙƒØ¯ = ØªÙƒØ±Ø§Ø± + Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¨Ù†ÙƒÙŠØ© 100%
        if len(analyzer.matched_df) > 0:
            matched_indices = analyzer.matched_df.index
            duplicates.loc[matched_indices, '_ConfirmedDuplicate'] = True
            duplicates.loc[matched_indices, 'ReasonText'] = 'ğŸ”´ ØªÙƒØ±Ø§Ø± Ù…Ø¤ÙƒØ¯ + Ø¨Ù†Ùƒ Ù…Ø·Ø§Ø¨Ù‚'
        
        # Update unmatched duplicates reason
        if len(analyzer.unmatched_df) > 0:
            unmatched_indices = analyzer.unmatched_df.index
            # Keep existing reason or update based on bank status
            for idx in unmatched_indices:
                if idx in duplicates.index:
                    bank_reason = analyzer.unmatched_df.loc[idx, 'MatchReason'] if 'MatchReason' in analyzer.unmatched_df.columns else ''
                    if bank_reason:
                        duplicates.loc[idx, 'ReasonText'] = f'âš ï¸ ØªÙƒØ±Ø§Ø± - {bank_reason}'
        
        # Update analyzer.duplicates with new info
        analyzer.duplicates = duplicates
        
    else:
        print("\nâš ï¸ ØªØ®Ø·ÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨Ù†Ùƒ (Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª)")
        analyzer.matched_df = pd.DataFrame()
        analyzer.unmatched_df = duplicates.copy() if len(duplicates) > 0 else pd.DataFrame()
    
    # Step 5: Generate strict reports
    print("\nğŸ“„ Ø§Ù„Ø®Ø·ÙˆØ© 5: Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©")
    print("-" * 80)
    
    generated_files = analyzer.generate_strict_reports()
    
    # Generate bank verification report
    if hasattr(analyzer, 'matched_df') and hasattr(analyzer, 'unmatched_df'):
        output_path = Path("outputs")
        timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
        bank_report_file = output_path / f"Strict_Bank_Verification_{timestamp}.xlsx"
        
        print(f"\nğŸ“ Ø§Ù„ØªÙ‚Ø±ÙŠØ± 2: ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨Ù†Ùƒ")
        print(f"   Ø§Ù„Ù…Ù„Ù: {bank_report_file.name}")
        
        with pd.ExcelWriter(bank_report_file, engine='openpyxl') as writer:
            # Sheet 1: Matched (100%)
            if len(analyzer.matched_df) > 0:
                export_cols_matched = [
                    'Season', 'Race', 'OwnerNumber', 'OwnerName', 'OwnerQatariId',
                    'AwardAmount', 'EntryDate', 'PaymentReference',
                    'BankTransferAmount', 'BankTransactionDate', 'BankBeneficiary',
                    'BankReference', 'BankIBAN',
                    'MatchStatus', 'MatchReason', 'AmountDifference',
                    '_DuplicateGroup', '_DuplicateCount'
                ]
                available = [c for c in export_cols_matched if c in analyzer.matched_df.columns]
                analyzer.matched_df[available].to_excel(writer, sheet_name='Matched_100%', index=False)
                print(f"   âœ… Ø³Ø¬Ù„Ø§Øª Ù…Ø·Ø§Ø¨Ù‚Ø© 100%: {len(analyzer.matched_df):,}")
            
            # Sheet 2: Unmatched
            if len(analyzer.unmatched_df) > 0:
                export_cols_unmatched = [
                    'Season', 'Race', 'OwnerNumber', 'OwnerName', 'OwnerQatariId',
                    'AwardAmount', 'EntryDate', 'PaymentReference',
                    'MatchStatus', 'MatchReason',
                    '_DuplicateGroup', '_DuplicateCount'
                ]
                available = [c for c in export_cols_unmatched if c in analyzer.unmatched_df.columns]
                analyzer.unmatched_df[available].to_excel(writer, sheet_name='Unmatched', index=False)
                print(f"   âŒ Ø³Ø¬Ù„Ø§Øª ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚Ø©: {len(analyzer.unmatched_df):,}")
            
            # Sheet 3: Verification summary
            summary_data = {
                'Metric': [
                    'Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©',
                    'Ø³Ø¬Ù„Ø§Øª Ù…Ø·Ø§Ø¨Ù‚Ø© 100%',
                    'Ø³Ø¬Ù„Ø§Øª ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚Ø©',
                    'Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©',
                    'Ù…Ø¹ÙŠØ§Ø± Ø§Ù„Ø¯Ù‚Ø©',
                    'Ø§Ù„ØªØ³Ø§Ù…Ø­ ÙÙŠ Ø§Ù„Ù…Ø¨Ù„Øº',
                    'Ø§Ù„ØªØ³Ø§Ù…Ø­ ÙÙŠ Ø§Ù„ØªØ§Ø±ÙŠØ®'
                ],
                'Value': [
                    len(duplicates),
                    len(analyzer.matched_df),
                    len(analyzer.unmatched_df),
                    f"{(len(analyzer.matched_df)/len(duplicates)*100):.1f}%" if len(duplicates) > 0 else "0%",
                    '100% (ØµØ§Ø±Ù…)',
                    '0.00 Ø±ÙŠØ§Ù„ (ØªØ·Ø§Ø¨Ù‚ ØªØ§Ù…)',
                    'ØºÙŠØ± Ù…Ø·Ø¨Ù‚ (Reference ÙÙ‚Ø·)'
                ]
            }
            pd.DataFrame(summary_data).to_excel(writer, sheet_name='Summary', index=False)
        
        print(f"   âœ… ØªÙ… Ø§Ù„Ø­ÙØ¸ Ø¨Ù†Ø¬Ø§Ø­")
        generated_files['bank_verification'] = str(bank_report_file)
    
    # Final summary
    print("\n" + "="*80)
    print("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„ØµØ§Ø±Ù…")
    print("="*80)
    print("\nğŸ“Š Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:")
    
    stats = analyzer.validation_report['statistics']
    
    if 'duplicates' in stats:
        dup_stats = stats['duplicates']
        print(f"\nğŸ” Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª:")
        print(f"   â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª: {dup_stats['total_records']:,}")
        print(f"   â€¢ Ø³Ø¬Ù„Ø§Øª Ù…ÙƒØ±Ø±Ø©: {dup_stats['total_duplicates']:,}")
        print(f"   â€¢ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„ØªÙƒØ±Ø§Ø±: {dup_stats['unique_groups']:,}")
        print(f"   â€¢ Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±: {dup_stats['duplicate_rate']:.2f}%")
        print(f"   â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¨Ø§Ù„Øº Ø§Ù„Ù…ÙƒØ±Ø±Ø©: {dup_stats['total_amount']:,.2f} Ø±ÙŠØ§Ù„")
    
    if 'bank_verification' in stats:
        bank_stats = stats['bank_verification']
        print(f"\nğŸ¦ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨Ù†Ùƒ:")
        print(f"   â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª: {bank_stats['total']:,}")
        print(f"   â€¢ âœ… Ù…Ø·Ø§Ø¨Ù‚ 100%: {bank_stats['matched']:,} ({bank_stats['match_rate']:.1f}%)")
        print(f"   â€¢ âŒ ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚: {bank_stats['unmatched']:,} ({100-bank_stats['match_rate']:.1f}%)")
    
    print(f"\nğŸ“ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…ÙÙ†Ø´Ø£Ø©:")
    for report_type, file_path in generated_files.items():
        print(f"   â€¢ {Path(file_path).name}")
    
    print("\n" + "="*80)
    print("ğŸ”’ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ù…Ø¹ØªÙ…Ø¯Ø© ÙˆÙ…ÙˆØ«ÙˆÙ‚Ø© Ø¨Ø¯Ù‚Ø© 100% Ù„Ù„Ø¬Ù‡Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ©")
    print("="*80)


if __name__ == "__main__":
    main()
