# -*- coding: utf-8 -*-
"""
ğŸš€ Data Analest - Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
===============================================
ØªØ·Ø¨ÙŠÙ‚ Ø§Ø­ØªØ±Ø§ÙÙŠ Ø¨ØªØµÙ…ÙŠÙ… UI Ø­Ø¯ÙŠØ« ÙŠØ¯Ø¹Ù… Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù„ÙŠÙ„ÙŠ ÙˆØ§Ù„Ù†Ù‡Ø§Ø±ÙŠ

Ø§Ù„Ù…Ø·ÙˆØ±: GitHub Copilot
Ø§Ù„ØªØ§Ø±ÙŠØ®: Ù†ÙˆÙÙ…Ø¨Ø± 2025
Ø§Ù„Ø¥ØµØ¯Ø§Ø±: 2.0.0
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
from pathlib import Path
import sys
import io

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
sys.path.append(str(Path(__file__).parent))

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
from core.data_loader import DataLoader
from core.duplicate_analyzer import DuplicateAnalyzer
from core.anomaly_detector import AnomalyDetector
from core.hr_analyzer import HRAnalyzer
from core.smart_test_generator import SmartTestGenerator
from utils.theme_manager import theme_manager
from utils.ui_components import UIComponents
import config

# ==================== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ====================
st.set_page_config(
    page_title="ğŸ’¼ Data Analest - Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://github.com/zahermasloub/Data_Analest',
        'Report a bug': 'https://github.com/zahermasloub/Data_Analest/issues',
        'About': '''
        # Data Analest v2.0.0
        Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ
        
        Ø§Ù„Ù…Ø·ÙˆØ±: GitHub Copilot
        '''
    }
)

# ==================== ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø«ÙŠÙ… ====================
theme_manager.inject_custom_css()

# ==================== ØªÙ‡ÙŠØ¦Ø© Session State ====================
if 'df' not in st.session_state:
    st.session_state.df = None
if 'loader' not in st.session_state:
    st.session_state.loader = None
if 'analysis_history' not in st.session_state:
    st.session_state.analysis_history = []
if 'current_page' not in st.session_state:
    st.session_state.current_page = "ğŸ  Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"
if 'merge_state' not in st.session_state:
    st.session_state.merge_state = {
        'file_a': None,
        'file_b': None,
        'df_a': None,
        'df_b': None,
        'keys': [],
        'merged_df': None,
        'report': None,
        'conflicts': None
    }

# ==================== Ù…ÙƒÙˆÙ†Ø§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© ====================
ui = UIComponents()

def save_analysis_to_history(analysis_type: str, result: dict):
    """Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„"""
    st.session_state.analysis_history.append({
        'timestamp': datetime.now(),
        'type': analysis_type,
        'result': result
    })

def process_file_upload(uploaded_file):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù"""
    try:
        with st.spinner('â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù...'):
            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
            temp_path = Path("uploads") / uploaded_file.name
            temp_path.parent.mkdir(exist_ok=True)
            
            with open(temp_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            loader = DataLoader(str(temp_path))
            loader.load()
            loader.auto_clean()
            
            st.session_state.df = loader.get_data()
            st.session_state.loader = loader
            
            st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(st.session_state.df):,} ØµÙ Ø¨Ù†Ø¬Ø§Ø­!")
            return True
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„: {str(e)}")
        return False

# ==================== Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ ====================
with st.sidebar:
    # Ø²Ø± ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„Ø«ÙŠÙ…
    theme = theme_manager.get_current_theme()
    theme_icon = "â˜€ï¸" if theme == "dark" else "ğŸŒ™"
    theme_text = "Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù†Ù‡Ø§Ø±ÙŠ" if theme == "dark" else "Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù„ÙŠÙ„ÙŠ"
    
    if st.button(f"{theme_icon} {theme_text}", use_container_width=True, key="theme_toggle"):
        theme_manager.toggle_theme()
    
    st.divider()
    
    # Ù‚Ø³Ù… Ø§Ù„ØªÙ†Ù‚Ù„
    ui.sidebar_section("ğŸ“‹ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©", "ğŸ§­")
    
    pages = [
        "ğŸ  Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
        "ğŸ§© ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…Ù„ÙØ§Øª",
        "ğŸ“¤ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª",
        "ğŸ‘¥ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¨Ø´Ø±ÙŠØ©",
        "ğŸ”§ ÙØ­ÙˆØµØ§Øª Ù…Ø®ØµØµØ©",
        "âœ… Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙØ­ÙˆØµØ§Øª",
        "ğŸ“Š Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…",
        "ğŸ“š Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…"
    ]
    
    page_icons = ["ğŸ ", "ğŸ“¤", "ğŸ‘¥", "ğŸ”§", "âœ…", "ğŸ“Š", "ğŸ“š"]
    
    for i, page in enumerate(pages):
        if st.button(page, use_container_width=True, key=f"nav_{i}"):
            st.session_state.current_page = page
    
    st.divider()
    
    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
    with st.expander("â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"):
        st.write("**Ø§Ù„Ø¥ØµØ¯Ø§Ø±:** 2.0.0")
        st.write("**Python:** 3.13")
        st.write("**Ø§Ù„Ø­Ø§Ù„Ø©:** âœ… Ø¬Ø§Ù‡Ø²")
        if st.session_state.df is not None:
            st.write(f"**Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:** {len(st.session_state.df):,} ØµÙ")
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©
    if st.session_state.df is not None:
        st.divider()
        st.markdown("### ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©")
        st.metric("Ø§Ù„ØµÙÙˆÙ", f"{len(st.session_state.df):,}")
        st.metric("Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©", len(st.session_state.df.columns))
        mem = st.session_state.df.memory_usage(deep=True).sum() / 1024**2
        st.metric("Ø§Ù„Ø­Ø¬Ù…", f"{mem:.2f} MB")

# ==================== Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ====================
current_page = st.session_state.current_page

# ==================== Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ====================
if current_page == "ğŸ  Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©":
    
    # Hero Section
    ui.hero_section(
        title="Data Analest",
        subtitle="Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…",
        description="Ù…Ù†ØµØ© Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ù…ØªÙƒØ§Ù…Ù„Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ù…Ø¹ ÙƒØ´Ù Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª ÙˆØ§Ù„Ø§Ù†Ø­Ø±Ø§ÙØ§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
        icon="ğŸ’¼"
    )
    
    # Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    st.markdown("## âœ¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        ui.feature_card(
            icon="ğŸ”",
            title="ÙƒØ´Ù Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª",
            description="Ø£Ù†Ø¸Ù…Ø© Ø°ÙƒÙŠØ© Ù…ØªØ¹Ø¯Ø¯Ø© Ù„ÙƒØ´Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©",
            features=[
                "âœ… ØªØ·Ø§Ø¨Ù‚ ØªØ§Ù… 100%",
                "âœ… ØªØ·Ø§Ø¨Ù‚ Ø¶Ø¨Ø§Ø¨ÙŠ 90%+",
                "âœ… ØªØ·Ø§Ø¨Ù‚ Ø¬Ø²Ø¦ÙŠ Ù…Ø±Ù†",
                "âœ… ØªØ­Ù„ÙŠÙ„ Ø²Ù…Ù†ÙŠ Ù…ØªÙ‚Ø¯Ù…"
            ]
        )
    
    with col2:
        ui.feature_card(
            icon="ğŸ“Š",
            title="ÙƒØ´Ù Ø§Ù„Ø§Ù†Ø­Ø±Ø§ÙØ§Øª",
            description="Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©",
            features=[
                "ğŸ“ˆ Ø·Ø±ÙŠÙ‚Ø© IQR Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ©",
                "ğŸ“‰ ØªØ­Ù„ÙŠÙ„ Z-Score",
                "ğŸ¤– Isolation Forest (AI)",
                "ğŸ¯ DBSCAN Clustering"
            ]
        )
    
    with col3:
        ui.feature_card(
            icon="ğŸ“„",
            title="ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ø­ØªØ±Ø§ÙÙŠØ©",
            description="ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø§Ø±ÙŠØ± Ø´Ø§Ù…Ù„Ø© ÙˆÙ…ÙØµÙ„Ø©",
            features=[
                "ğŸ“Š ØªØµØ¯ÙŠØ± Excel Ù…Ù†Ø³Ù‚",
                "ğŸ“ˆ Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ© ØªÙØ§Ø¹Ù„ÙŠØ©",
                "ğŸ’¾ Ø­ÙØ¸ ØªÙ„Ù‚Ø§Ø¦ÙŠ",
                "ğŸ“± ÙˆØ§Ø¬Ù‡Ø© Ø³Ø±ÙŠØ¹Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©"
            ]
        )
    
    st.divider()
    
    # Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø¨Ø¯Ø¡
    ui.timeline_card(
        title="ğŸš€ ÙƒÙŠÙ ØªØ¨Ø¯Ø£ØŸ",
        items=[
            {"title": "Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù", "description": "Ø§Ù†ØªÙ‚Ù„ Ø¥Ù„Ù‰ Ù‚Ø³Ù… 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª' ÙˆØ§Ø±ÙØ¹ Ù…Ù„Ù Excel Ø£Ùˆ CSV"},
            {"title": "Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„", "description": "Ø­Ø¯Ø¯ Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: ØªÙƒØ±Ø§Ø±Ø§ØªØŒ Ø§Ù†Ø­Ø±Ø§ÙØ§ØªØŒ Ø£Ùˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª"},
            {"title": "Ø¶Ø¨Ø· Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª", "description": "Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­Ù„ÙŠÙ„Ù‡Ø§ ÙˆØ¶Ø¨Ø· Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª"},
            {"title": "Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", "description": "Ø´Ø§Ù‡Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø´ÙƒÙ„ ØªÙØ§Ø¹Ù„ÙŠ ÙˆÙ‚Ù… Ø¨ØªØµØ¯ÙŠØ±Ù‡Ø§"},
            {"title": "ØªØµØ¯ÙŠØ± Ø§Ù„ØªÙ‚Ø±ÙŠØ±", "description": "Ø­Ù…Ù‘Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙƒØ§Ù…Ù„ Ø¨ØµÙŠØºØ© Excel Ø£Ùˆ PDF"}
        ]
    )
    
    st.divider()
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
    st.markdown("## ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        ui.metric_card("Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø«Ø¨ØªØ©", "60+", "âœ… Ø¬Ø§Ù‡Ø²Ø©", "ğŸ“¦")
    
    with col2:
        ui.metric_card("Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­", "100%", "6/6 ÙØ­ÙˆØµØ§Øª", "â­")
    
    with col3:
        ui.metric_card("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø®ØªØ¨Ø±Ø©", "28,636", "ØµÙ", "ğŸ“ˆ")
    
    with col4:
        ui.metric_card("Ø§Ù„ØªÙ‚ÙŠÙŠÙ…", "5/5", "Ù…Ù…ØªØ§Ø²", "ğŸ†")
# ==================== ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…Ù„ÙØ§Øª (Ø¯Ù…Ø¬ Ù†Ø¸ÙŠÙ) ====================
elif current_page == "ğŸ§© ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…Ù„ÙØ§Øª":
    # Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„ÙˆØµÙ (Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù…Ø¹ÙŠØ§Ø± Ø§Ù„ØµÙØ­Ø©)
    ui.gradient_header("ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…Ù„ÙØ§Øª", "Ø§Ø¯Ù…Ø¬ Ù…Ù„ÙÙŠ Excel ÙÙŠ Ù…Ù„Ù Ù…ÙˆØ­Ù‘Ø¯ Ø¯ÙˆÙ† ØªÙƒØ±Ø§Ø± Ù„Ù„ØµÙÙˆÙØŒ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø© ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª.", "ğŸ§©")

    # Ù…Ù†Ø·Ù‚Ø© Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª (Ù…Ù„Ù Ø£ÙˆÙ„ ÙˆØ«Ø§Ù†Ù)
    st.markdown("### ğŸ“")
    col_a, col_b = st.columns(2)
    with col_a:
        file_a = st.file_uploader("Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ÙˆÙ„", type=['xlsx', 'xls', 'csv'], key="merge_file_a")
    with col_b:
        file_b = st.file_uploader("Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø«Ø§Ù†ÙŠ", type=['xlsx', 'xls', 'csv'], key="merge_file_b")

    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ø¹Ø¯ Ø§Ù„Ø±ÙØ¹
    read_error = None
    if file_a is not None:
        try:
            if file_a.name.lower().endswith('.csv'):
                st.session_state.merge_state['df_a'] = pd.read_csv(file_a)
            else:
                st.session_state.merge_state['df_a'] = pd.read_excel(file_a)
            st.session_state.merge_state['file_a'] = file_a.name
        except Exception:
            read_error = "Ø§Ù„Ù…Ù„ÙØ§Øª ØºÙŠØ± ØµØ§Ù„Ø­Ø© Ø£Ùˆ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…."
    if file_b is not None:
        try:
            if file_b.name.lower().endswith('.csv'):
                st.session_state.merge_state['df_b'] = pd.read_csv(file_b)
            else:
                st.session_state.merge_state['df_b'] = pd.read_excel(file_b)
            st.session_state.merge_state['file_b'] = file_b.name
        except Exception:
            read_error = "Ø§Ù„Ù…Ù„ÙØ§Øª ØºÙŠØ± ØµØ§Ù„Ø­Ø© Ø£Ùˆ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…."

    if read_error:
        ui.info_box("Ø®Ø·Ø£", read_error, "error")

    df_a = st.session_state.merge_state.get('df_a')
    df_b = st.session_state.merge_state.get('df_b')

    if df_a is not None and df_b is not None:
        st.divider()

        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø¯Ù…Ø¬
        st.markdown("### ğŸ“‹")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            ui.metric_card("Ø¥Ø¬Ù…Ø§Ù„ÙŠ ØµÙÙˆÙ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ÙˆÙ„:", f"{len(df_a):,}", "", "ğŸ“„")
        with col2:
            ui.metric_card("Ø¥Ø¬Ù…Ø§Ù„ÙŠ ØµÙÙˆÙ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø«Ø§Ù†ÙŠ:", f"{len(df_b):,}", "", "ğŸ“„")
        with col3:
            ui.metric_card("Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©", str(len(set(df_a.columns).intersection(set(df_b.columns)))), "", "ğŸ”—")
        with col4:
            ui.metric_card("Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ", f"{(df_a.memory_usage(deep=True).sum()+df_b.memory_usage(deep=True).sum())/1024**2:.2f} MB", "", "ğŸ’¾")

        # Ù…Ø¹Ø§ÙŠÙ†Ø© Ø¹ÙŠÙ†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„ÙÙŠÙ†
        with st.expander("ğŸ‘€ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø¹ÙŠÙ†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø¯Ù…Ø¬", expanded=False):
            st.markdown("#### Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ÙˆÙ„")
            ui.data_table_enhanced(df_a.head(10), show_search=False)
            st.markdown("#### Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø«Ø§Ù†ÙŠ")
            ui.data_table_enhanced(df_b.head(10), show_search=False)

        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ (Ù„Ø§ Ù†Ø¹Ø±Ø¶ Ù†ØµÙˆØµ Ø¥Ø¶Ø§ÙÙŠØ© ØºÙŠØ± Ù…Ø°ÙƒÙˆØ±Ø©)
        common_cols = [c for c in df_a.columns if c in df_b.columns]
        preferred = ["Ø±Ù‚Ù… Ø§Ù„Ù‡ÙˆÙŠØ©", "Ø±Ù‚Ù… Ø§Ù„Ø³Ø¨Ø§Ù‚", "Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø§Ù„Ù…Ø¨Ù„Øº"]
        default_keys = [c for c in preferred if c in common_cols]
        if not default_keys:
            default_keys = common_cols[:2] if len(common_cols) >= 2 else common_cols

        # Ø¹Ù†ØµØ± Ø§Ø®ØªÙŠØ§Ø± Ø¨Ø¯ÙˆÙ† ØªØ³Ù…ÙŠØ© Ù†ØµÙŠØ© Ø¥Ø¶Ø§ÙÙŠØ©
        selected_keys = st.multiselect(" ", options=common_cols, default=default_keys, key="merge_keys")
        st.caption("Ø§Ø®ØªÙŠØ§Ø±ÙŠ: ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ø¯ÙŠØ¯ Ø£Ø¹Ù…Ø¯Ø© Ù„Ù„ØªØ·Ø§Ø¨Ù‚ØŒ ÙˆØ¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ¯ Ø³ÙŠØªÙ… Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹.")

        # Ø²Ø± ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯Ù…Ø¬
        run_merge = st.button("ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯Ù…Ø¬", use_container_width=True, key="run_clean_merge")

        if run_merge:
            try:
                with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¯Ù…Ø¬â€¦"):
                    # Ù†Ø³Ø® Ù„Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø£ØµÙ„
                    A = df_a.copy()
                    B = df_b.copy()

                    # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„ØªØ´Ù…Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ„
                    all_cols = list(dict.fromkeys(list(A.columns) + list(B.columns)))
                    for col in all_cols:
                        if col not in A.columns:
                            A[col] = pd.NA
                        if col not in B.columns:
                            B[col] = pd.NA

                    if len(selected_keys) == 0:
                        # Ø¯Ù…Ø¬ ÙƒØ§Ù…Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ (ØªØ·Ø§Ø¨Ù‚ Ø§Ù„ØµÙ Ø¹Ù†Ø¯ ØªØ·Ø§Ø¨Ù‚ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©)
                        a_unique = A.drop_duplicates()
                        b_unique = B.drop_duplicates()
                        merged_all = pd.concat([a_unique, b_unique], ignore_index=True)
                        deduped = merged_all.drop_duplicates()

                        # Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                        # Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù…Ù† B Ø§Ù„ØªÙŠ Ù„ÙŠØ³Øª ÙÙŠ A (ØªØ·Ø§Ø¨Ù‚ ÙƒØ§Ù…Ù„ Ù„Ù„Ø£Ø¹Ù…Ø¯Ø©)
                        new_merge = b_unique.merge(a_unique, how='left', on=all_cols, indicator=True)
                        new_rows_count = int((new_merge['_merge'] == 'left_only').sum()) if '_merge' in new_merge.columns else 0
                        duplicates_removed_count = len(merged_all) - len(deduped)

                        merged_df = deduped
                        conflicts_list = []
                        auto_filled_updates = 0
                        keys_used = []
                    else:
                        # Ø­ÙØ¸ Ø§Ù„Ù…ÙØ§ØªÙŠØ­
                        st.session_state.merge_state['keys'] = selected_keys

                        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…ÙØ§ØªÙŠØ­
                        key_tuple_a = A[selected_keys].astype(str).apply(lambda r: tuple(r.values.tolist()), axis=1)
                        key_tuple_b = B[selected_keys].astype(str).apply(lambda r: tuple(r.values.tolist()), axis=1)

                        set_a = set(key_tuple_a)
                        set_b = set(key_tuple_b)

                        only_in_b_keys = set_b - set_a
                        in_both_keys = set_a & set_b

                        # Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø§Ù„Ù…Ø¶Ø§ÙØ© (Ø­Ø³Ø¨ Ø§Ù„Ù…ÙØ§ØªÙŠØ­)
                        idx_b_only = [i for i, k in enumerate(key_tuple_b) if k in only_in_b_keys]
                        new_rows = B.iloc[idx_b_only].copy()

                        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ù„ÙÙŠÙ† (ØªØ¹Ø§Ø±Ø¶/ØªÙƒØ±Ø§Ø±)
                        conflicts_list = []
                        duplicates_removed_count = 0
                        auto_filled_updates = 0

                        # Ø®Ø±ÙŠØ·Ø© Ù…Ù† Ø§Ù„Ù…ÙØªØ§Ø­ Ø¥Ù„Ù‰ ØµÙ ÙÙŠ B Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„ÙˆØµÙˆÙ„
                        b_map = {}
                        for i, k in enumerate(key_tuple_b):
                            if k in in_both_keys:
                                b_map.setdefault(k, []).append(i)

                        # Ø§Ù„Ù…Ø±ÙˆØ± Ø¹Ù„Ù‰ ØµÙÙˆÙ A ÙˆØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø¬Ø²Ø¦ÙŠ
                        for i, k in enumerate(key_tuple_a):
                            if k in in_both_keys:
                                b_indices = b_map.get(k, [])
                                if not b_indices:
                                    continue
                                j = b_indices[0]
                                row_a = A.iloc[i]
                                row_b = B.iloc[j]

                                diff_cols = []
                                identical_all = True
                                for col in all_cols:
                                    if col in selected_keys:
                                        continue
                                    va = row_a[col]
                                    vb = row_b[col]

                                    is_na_a = pd.isna(va) or (isinstance(va, str) and va.strip() == "")
                                    is_na_b = pd.isna(vb) or (isinstance(vb, str) and vb.strip() == "")

                                    if is_na_a and not is_na_b:
                                        A.at[A.index[i], col] = vb
                                        auto_filled_updates += 1
                                        identical_all = False
                                    elif (not is_na_a and not is_na_b) and (str(va) != str(vb)):
                                        identical_all = False
                                        diff_cols.append(col)

                                if identical_all:
                                    duplicates_removed_count += 1
                                elif len(diff_cols) > 0:
                                    conflict_entry = {
                                        'keys': {kname: row_a[kname] for kname in selected_keys},
                                        'Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„Ø­Ù‚ÙˆÙ„': []
                                    }
                                    for dc in diff_cols:
                                        conflict_entry['Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„Ø­Ù‚ÙˆÙ„'].append({
                                            'Ø§Ù„Ø­Ù‚Ù„': dc,
                                            'Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ÙˆÙ„': row_a[dc],
                                            'Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø«Ø§Ù†ÙŠ': row_b[dc]
                                        })
                                    conflicts_list.append(conflict_entry)

                        merged_df = pd.concat([A, new_rows], ignore_index=True)
                        new_rows_count = len(new_rows)
                        keys_used = selected_keys

                    # ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ù…ÙˆØ­Ø¯
                    report = {
                        'timestamp': datetime.now().isoformat(),
                        'keys_used': keys_used,
                        'totals': {
                            'file_a_rows': len(df_a),
                            'file_b_rows': len(df_b),
                            'new_rows_added': new_rows_count,
                            'duplicates_removed': duplicates_removed_count,
                            'conflicts': len(conflicts_list),
                            'auto_filled_updates': auto_filled_updates
                        },
                        'conflicts': conflicts_list
                    }

                    st.session_state.merge_state['merged_df'] = merged_df
                    st.session_state.merge_state['report'] = report
                    st.session_state.merge_state['conflicts'] = conflicts_list

                # Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­ ÙˆÙÙ‚ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª
                st.success("ØªÙ… Ø§Ù„Ø¯Ù…Ø¬ Ø¨Ù†Ø¬Ø§Ø­ ÙˆÙÙ‚ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª.")
                if len(selected_keys) == 0:
                    st.info("ØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù„Ø¹Ø¯Ù… ØªØ­Ø¯ÙŠØ¯ Ø£Ø¹Ù…Ø¯Ø© ØªØ·Ø§Ø¨Ù‚.")

            except Exception:
                ui.info_box("Ø®Ø·Ø£", "ØªØ¹Ø°Ù‘Ø± Ø¥ØªÙ…Ø§Ù… Ø§Ù„Ø¹Ù…Ù„ÙŠØ© â€” ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø£Ùˆ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©.", "error")

        # Ø¥Ø¸Ù‡Ø§Ø± Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø¥Ø°Ø§ ØªÙˆÙØ± Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        if st.session_state.merge_state.get('report') is not None:
            st.divider()
            totals = st.session_state.merge_state['report']['totals']

            # Ù„ÙˆØ­Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            st.markdown("### ğŸ“Š")
            r1, r2, r3, r4, r5 = st.columns(5)
            with r1:
                ui.metric_card("Ø¥Ø¬Ù…Ø§Ù„ÙŠ ØµÙÙˆÙ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ÙˆÙ„:", f"{totals['file_a_rows']:,}", "", "ğŸ“„")
            with r2:
                ui.metric_card("Ø¥Ø¬Ù…Ø§Ù„ÙŠ ØµÙÙˆÙ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø«Ø§Ù†ÙŠ:", f"{totals['file_b_rows']:,}", "", "ğŸ“„")
            with r3:
                ui.metric_card("Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø§Ù„Ù…Ø¶Ø§ÙØ©:", f"{totals['new_rows_added']:,}", "", "â•")
            with r4:
                ui.metric_card("Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ø§Ù„Ù…Ø­Ø°ÙˆÙØ©:", f"{totals['duplicates_removed']:,}", "", "â™»ï¸")
            with r5:
                ui.metric_card("Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø§Ù„ØªÙŠ ØªØªØ·Ù„Ø¨ Ù…Ø±Ø§Ø¬Ø¹Ø©:", f"{totals['conflicts']:,}", "", "âš ï¸")

            if totals['new_rows_added'] == 0 and totals['duplicates_removed'] == 0 and totals['conflicts'] == 0:
                ui.info_box("ØªÙ†Ø¨ÙŠÙ‡", "Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙÙˆÙ Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø¯Ù…Ø¬.", "warning")

            # Ø£Ø²Ø±Ø§Ø± Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª
            c1, c2 = st.columns(2)
            with c1:
                # ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ­Ù‘Ø¯
                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                    st.session_state.merge_state['merged_df'].to_excel(writer, index=False, sheet_name='Unified')
                st.download_button(
                    label="ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ­Ù‘Ø¯",
                    data=buffer.getvalue(),
                    file_name=f"unified_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
            with c2:
                # Ø¹Ø±Ø¶ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø¯Ù…Ø¬ (ÙƒÙ„ÙˆØ­Ø© Ø¬Ø§Ù†Ø¨ÙŠØ©/Ù…ÙˆØ³Ø¹)
                show_report = st.toggle("Ø¹Ø±Ø¶ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø¯Ù…Ø¬", value=False, key="show_merge_report")

            if show_report:
                with st.expander("ØªØ¹Ø§Ø±Ø¶Ø§Øª ØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø©", expanded=True):
                    conflicts = st.session_state.merge_state.get('conflicts', [])
                    if len(conflicts) == 0:
                        st.write("Ù„Ø§ ØªÙˆØ¬Ø¯ ØªØ¹Ø§Ø±Ø¶Ø§Øª.")
                    else:
                        # Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ Ù…Ø¨Ø³Ù‘Ø· Ù„Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª
                        rows = []
                        for c in conflicts:
                            key_vals = " | ".join([f"{k}:{v}" for k, v in c['keys'].items()])
                            for diff in c['Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„Ø­Ù‚ÙˆÙ„']:
                                rows.append({
                                    'Ø§Ù„Ù…ÙØ§ØªÙŠØ­': key_vals,
                                    'Ø§Ù„Ø­Ù‚Ù„': diff['Ø§Ù„Ø­Ù‚Ù„'],
                                    'Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ÙˆÙ„': diff['Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ÙˆÙ„'],
                                    'Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø«Ø§Ù†ÙŠ': diff['Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø«Ø§Ù†ÙŠ']
                                })
                        if rows:
                            ui.data_table_enhanced(pd.DataFrame(rows), show_search=False)

                        # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© (Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ù…Ø³ØªÙˆÙ‰)
                        st.markdown("---")
                        st.markdown("#### ØªØ¹Ø§Ø±Ø¶Ø§Øª ØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø©")
                        option = st.radio(
                            " ",
                            ["Ø§Ø®ØªÙŠØ§Ø± Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ÙˆÙ„", "Ø§Ø®ØªÙŠØ§Ø± Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø«Ø§Ù†ÙŠ", "Ø¯Ù…Ø¬ Ø§Ù†ØªÙ‚Ø§Ø¦ÙŠ Ù„Ù„Ø­Ù‚Ù„"],
                            index=0,
                            horizontal=True,
                            key="conflict_resolution_choice"
                        )
                        # ØªØ·Ø¨ÙŠÙ‚ Ù‚Ø±Ø§Ø± Ø¹Ø§Ù… (Ø§Ø®ØªÙŠØ§Ø±ÙŠ): Ù„ØªØ¨Ø³ÙŠØ·ØŒ Ù†Ø·Ø¨Ù‘Ù‚ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª
                        apply = st.button("ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‚Ø±Ø§Ø±", use_container_width=True, key="apply_conflict_resolution")
                        if apply and option in ["Ø§Ø®ØªÙŠØ§Ø± Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ÙˆÙ„", "Ø§Ø®ØªÙŠØ§Ø± Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø«Ø§Ù†ÙŠ"]:
                            merged = st.session_state.merge_state['merged_df']
                            keys = st.session_state.merge_state['keys']
                            # Ø¨Ù†Ø§Ø¡ ÙÙ‡Ø±Ø³ Ù…Ø±ÙƒØ¨ Ù„Ù„Ù…ÙØ§ØªÙŠØ­
                            def make_key_tuple(df):
                                return df[keys].astype(str).apply(lambda r: tuple(r.values.tolist()), axis=1)
                            m_keys = make_key_tuple(merged)
                            A = df_a.copy()
                            B = df_b.copy()
                            a_map = {}
                            for i, k in enumerate(A[keys].astype(str).apply(lambda r: tuple(r.values.tolist()), axis=1)):
                                a_map[k] = i
                            b_map2 = {}
                            for i, k in enumerate(B[keys].astype(str).apply(lambda r: tuple(r.values.tolist()), axis=1)):
                                b_map2[k] = i
                            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‚Ø±Ø§Ø±
                            for conf in st.session_state.merge_state['conflicts']:
                                kdict = conf['keys']
                                kt = tuple([str(kdict[kname]) for kname in keys])
                                # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØµÙ Ù…ÙˆØ­Ù‘Ø¯ Ù…Ø·Ø§Ø¨Ù‚
                                try:
                                    m_idx = list(m_keys).index(kt)
                                except ValueError:
                                    continue
                                for diff in conf['Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„Ø­Ù‚ÙˆÙ„']:
                                    col = diff['Ø§Ù„Ø­Ù‚Ù„']
                                    if option == "Ø§Ø®ØªÙŠØ§Ø± Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ÙˆÙ„":
                                        merged.at[merged.index[m_idx], col] = diff['Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ÙˆÙ„']
                                    elif option == "Ø§Ø®ØªÙŠØ§Ø± Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø«Ø§Ù†ÙŠ":
                                        merged.at[merged.index[m_idx], col] = diff['Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø«Ø§Ù†ÙŠ']
                            st.session_state.merge_state['merged_df'] = merged
                            ui.info_box("Ù†Ø¬Ø§Ø­", "ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª.", "success")

    else:
        ui.empty_state(
            icon="ğŸ§©",
            title="ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…Ù„ÙØ§Øª",
            description="Ø§Ø¯Ù…Ø¬ Ù…Ù„ÙÙŠ Excel ÙÙŠ Ù…Ù„Ù Ù…ÙˆØ­Ù‘Ø¯ Ø¯ÙˆÙ† ØªÙƒØ±Ø§Ø± Ù„Ù„ØµÙÙˆÙØŒ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø© ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª."
        )

# ==================== ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª ====================
elif current_page == "ğŸ“¤ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª":
    
    ui.gradient_header("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª", "Ø§Ø±ÙØ¹ Ù…Ù„ÙÙƒ ÙˆØ§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙˆØ±Ø§Ù‹", "ğŸ“¤")
    
    # Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù
    st.markdown("### ğŸ“ Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù")
    
    uploaded_file = st.file_uploader(
        "Ø§Ø®ØªØ± Ù…Ù„Ù Excel Ø£Ùˆ CSV",
        type=['xlsx', 'xls', 'csv'],
        help="Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø­Ø¬Ù…: 500 Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª"
    )
    
    if uploaded_file:
        if st.session_state.df is None:
            process_file_upload(uploaded_file)
        
        if st.session_state.df is not None:
            df = st.session_state.df
            
            st.divider()
            
            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„Ù
            st.markdown("### ğŸ“‹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„Ù")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                ui.metric_card("Ø§Ù„ØµÙÙˆÙ", f"{len(df):,}", "", "ğŸ“Š")
            with col2:
                ui.metric_card("Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©", str(len(df.columns)), "", "ğŸ“‹")
            with col3:
                mem = df.memory_usage(deep=True).sum() / 1024**2
                ui.metric_card("Ø§Ù„Ø­Ø¬Ù…", f"{mem:.2f} MB", "", "ğŸ’¾")
            with col4:
                null_pct = (df.isnull().sum().sum() / (len(df) * len(df.columns)) * 100)
                ui.metric_card("Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ©", f"{null_pct:.1f}%", "", "âš ï¸")
            
            st.divider()
            
            # Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            with st.expander("ğŸ‘€ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", expanded=False):
                ui.data_table_enhanced(df.head(20), max_height=400)
            
            st.divider()
            
            # Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„
            st.markdown("### ğŸ¯ Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
            
            analysis_tabs = ui.tabs_enhanced(
                ["ÙƒØ´Ù Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª", "ÙƒØ´Ù Ø§Ù„Ø§Ù†Ø­Ø±Ø§ÙØ§Øª", "Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª", "ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„"],
                ["ğŸ”", "ğŸ“‰", "ğŸ“Š", "ğŸ¨"]
            )
            
            # ========== ÙƒØ´Ù Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª ==========
            with analysis_tabs[0]:
                st.markdown("#### ğŸ” ÙƒØ´Ù Ø§Ù„Ø¯ÙØ¹Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©")
                
                # Ø§Ø®ØªÙŠØ§Ø± Ù…ØªØ¹Ø¯Ø¯ Ù„Ù„Ø­Ù‚ÙˆÙ„
                st.markdown("##### ğŸ“‹ Ø§Ø®ØªØ± Ø§Ù„Ø­Ù‚ÙˆÙ„ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©:")
                selected_columns = st.multiselect(
                    "Ø§Ø®ØªØ± Ø­Ù‚Ù„ ÙˆØ§Ø­Ø¯ Ø£Ùˆ Ø£ÙƒØ«Ø± Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„ÙŠÙ‡Ø§:",
                    options=df.columns.tolist(),
                    default=df.columns.tolist()[:2] if len(df.columns) >= 2 else df.columns.tolist(),
                    key="dup_columns",
                    help="ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø®ØªÙŠØ§Ø± Ø­Ù‚Ù„ ÙˆØ§Ø­Ø¯ Ø£Ùˆ Ø£ÙƒØ«Ø±. Ø³ÙŠØªÙ… Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªÙŠ ØªØªØ·Ø§Ø¨Ù‚ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©."
                )
                
                col1, col2 = st.columns(2)
                
                with col1:
                    date_col = st.selectbox(
                        "Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ§Ø±ÙŠØ® (Ø§Ø®ØªÙŠØ§Ø±ÙŠ):",
                        options=["Ù„Ø§ ÙŠÙˆØ¬Ø¯"] + df.columns.tolist(),
                        key="dup_date",
                        help="Ø§Ø®ØªØ± Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø¶Ù…Ù† Ù†Ø§ÙØ°Ø© Ø²Ù…Ù†ÙŠØ© Ù…Ø¹ÙŠÙ†Ø©"
                    )
                
                with col2:
                    if date_col != "Ù„Ø§ ÙŠÙˆØ¬Ø¯":
                        time_window = st.number_input(
                            "Ø§Ù„Ù†Ø§ÙØ°Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© (Ø¨Ø§Ù„Ø£ÙŠØ§Ù…):",
                            min_value=1,
                            max_value=365,
                            value=30,
                            key="dup_time_window",
                            help="Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø®Ù„Ø§Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø¯Ø¯ Ù…Ù† Ø§Ù„Ø£ÙŠØ§Ù…"
                        )
                    else:
                        time_window = None
                
                if st.button("ğŸš€ Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø¨Ø­Ø«", key="run_dup", use_container_width=True):
                    if not selected_columns:
                        st.error("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø­Ù‚Ù„ ÙˆØ§Ø­Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©")
                    else:
                        with st.spinner("ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª..."):
                            analyzer = DuplicateAnalyzer(df)
                            
                            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ØªØ¹Ø¯Ø¯
                            if len(selected_columns) == 2 and date_col == "Ù„Ø§ ÙŠÙˆØ¬Ø¯":
                                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø­Ù‚Ù„ÙŠÙ† ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† ØªØ§Ø±ÙŠØ®
                                duplicates = analyzer.find_payment_duplicates(
                                    selected_columns[0], 
                                    selected_columns[1]
                                )
                            else:
                                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ØªØ¹Ø¯Ø¯
                                duplicates = analyzer.find_exact_duplicates(subset=selected_columns)
                        
                        if len(duplicates) > 0:
                            st.success(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(duplicates):,} ØªÙƒØ±Ø§Ø±")
                            
                            # Ø¹Ø±Ø¶ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
                            st.info(f"ğŸ“ **Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©:** {', '.join(selected_columns)}")
                            
                            # Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                ui.metric_card("Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª", f"{len(duplicates):,}", "", "ğŸ”¢")
                            with col2:
                                ui.metric_card("Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª", str(duplicates['duplicate_group'].nunique()), "", "ğŸ‘¥")
                            with col3:
                                pct = len(duplicates)/len(df)*100
                                ui.metric_card("Ø§Ù„Ù†Ø³Ø¨Ø©", f"{pct:.2f}%", "", "ğŸ“Š")
                            
                            st.divider()
                            
                            # Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                            ui.data_table_enhanced(duplicates, "ğŸ“‹ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©")
                            
                            # Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
                            st.divider()
                            fig = px.bar(
                                duplicates.groupby('duplicate_group').size().reset_index(name='count'),
                                x='duplicate_group',
                                y='count',
                                title='ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©',
                                color='count',
                                color_continuous_scale='Viridis'
                            )
                            ui.chart_card(fig, description="Ø¹Ø¯Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª ÙÙŠ ÙƒÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø©")
                            
                            # ØªØµØ¯ÙŠØ±
                            output = io.BytesIO()
                            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                                duplicates.to_excel(writer, index=False)
                            
                            st.download_button(
                                label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± (Excel)",
                                data=output.getvalue(),
                                file_name=f"duplicates_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                use_container_width=True
                            )
                        else:
                            ui.info_box("Ù…Ø¹Ù„ÙˆÙ…Ø©", "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ ØªÙƒØ±Ø§Ø±Ø§Øª ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª âœ…", "info")
            
            # ========== ÙƒØ´Ù Ø§Ù„Ø§Ù†Ø­Ø±Ø§ÙØ§Øª ==========
            with analysis_tabs[1]:
                st.markdown("#### ğŸ“‰ ÙƒØ´Ù Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©")
                
                numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
                
                if numeric_cols:
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        selected_col = st.selectbox(
                            "Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù…ÙˆØ¯:",
                            options=numeric_cols,
                            key="anom_col"
                        )
                    
                    with col2:
                        method = st.selectbox(
                            "Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©:",
                            options=["IQR", "Z-Score", "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ø±Ù‚"],
                            key="anom_method"
                        )
                    
                    if st.button("ğŸš€ ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ°Ø§Øª", key="run_anom", use_container_width=True):
                        with st.spinner("ğŸ“‰ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„..."):
                            detector = AnomalyDetector(df)
                            
                            if method == "IQR":
                                anomalies = detector.detect_iqr_anomalies(selected_col)
                            elif method == "Z-Score":
                                anomalies = detector.detect_zscore_anomalies(selected_col)
                            else:
                                results = detector.detect_all_anomalies(selected_col)
                                anomalies = detector.anomalies
                            
                            if len(anomalies) > 0:
                                st.success(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(anomalies):,} Ø´Ø°ÙˆØ°")
                                
                                # Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    ui.metric_card("Ø§Ù„Ø´Ø°ÙˆØ°Ø§Øª", f"{len(anomalies):,}", "", "ğŸ”¢")
                                with col2:
                                    pct = len(anomalies)/len(df)*100
                                    ui.metric_card("Ø§Ù„Ù†Ø³Ø¨Ø©", f"{pct:.2f}%", "", "ğŸ“Š")
                                with col3:
                                    ui.metric_card("Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©", method, "", "ğŸ”¬")
                                
                                st.divider()
                                
                                # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                                ui.data_table_enhanced(anomalies, "ğŸ“‹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©")
                                
                                # Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
                                st.divider()
                                fig = px.scatter(
                                    df,
                                    y=selected_col,
                                    title=f'ğŸ“‰ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ… ÙÙŠ {selected_col}',
                                    color=df.index.isin(anomalies.index),
                                    labels={'color': 'Ø´Ø§Ø°'}
                                )
                                ui.chart_card(fig)
                            else:
                                ui.info_box("Ù…Ø¹Ù„ÙˆÙ…Ø©", "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø´Ø°ÙˆØ°Ø§Øª âœ…", "info")
                else:
                    ui.info_box("ØªÙ†Ø¨ÙŠÙ‡", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© Ø±Ù‚Ù…ÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„", "warning")
            
            # ========== Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ==========
            with analysis_tabs[2]:
                st.markdown("#### ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ")
                
                numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
                
                if numeric_cols:
                    selected_cols = st.multiselect(
                        "Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©:",
                        options=numeric_cols,
                        default=numeric_cols[:3] if len(numeric_cols) >= 3 else numeric_cols
                    )
                    
                    if selected_cols and st.button("ğŸ“Š ØªØ­Ù„ÙŠÙ„", key="run_stats", use_container_width=True):
                        for col in selected_cols:
                            st.markdown(f"### ğŸ“ˆ {col}")
                            
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                stats = df[col].describe()
                                ui.stats_card({
                                    "Ø§Ù„Ù…ØªÙˆØ³Ø·": f"{stats['mean']:,.2f}",
                                    "Ø§Ù„ÙˆØ³ÙŠØ·": f"{df[col].median():,.2f}",
                                    "Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ": f"{stats['std']:,.2f}",
                                    "Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰": f"{stats['min']:,.2f}",
                                    "Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰": f"{stats['max']:,.2f}"
                                })
                            
                            with col2:
                                fig = px.histogram(df, x=col, nbins=30, title=f"ØªÙˆØ²ÙŠØ¹ {col}")
                                ui.chart_card(fig)
                            
                            st.divider()
                else:
                    ui.info_box("ØªÙ†Ø¨ÙŠÙ‡", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© Ø±Ù‚Ù…ÙŠØ©", "warning")
            
            # ========== ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ ==========
            with analysis_tabs[3]:
                ui.info_box(
                    "Ù‚Ø±ÙŠØ¨Ø§Ù‹",
                    "Ø³ÙŠØªÙ… Ø¥Ø¶Ø§ÙØ© Ù…ÙŠØ²Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù‚Ø±ÙŠØ¨Ø§Ù‹ ğŸš€",
                    "info"
                )
    
    else:
        ui.empty_state(
            icon="ğŸ“",
            title="Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ø£ÙŠ Ù…Ù„Ù",
            description="Ø§Ø±ÙØ¹ Ù…Ù„Ù Excel Ø£Ùˆ CSV Ù„Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„"
        )

# ==================== Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¨Ø´Ø±ÙŠØ© ====================
elif current_page == "ğŸ‘¥ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¨Ø´Ø±ÙŠØ©":
    
    ui.gradient_header("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¨Ø´Ø±ÙŠØ©", "ÙØ­ÙˆØµØ§Øª Ù…ØªØ®ØµØµØ© Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†", "ğŸ‘¥")
    
    # Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù
    st.markdown("### ğŸ“ Ø±ÙØ¹ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†")
    
    hr_file = st.file_uploader(
        "Ø§Ø®ØªØ± Ù…Ù„Ù Excel Ø£Ùˆ CSV Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†",
        type=['csv', 'xlsx', 'xls'],
        key="hr_file",
        help="Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø­Ø¬Ù…: 500 Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª"
    )
    
    if hr_file:
        try:
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
            if hr_file.name.endswith('.csv'):
                hr_df = pd.read_csv(hr_file)
            else:
                hr_df = pd.read_excel(hr_file)
            
            st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(hr_df):,} Ø³Ø¬Ù„ Ø¨Ù†Ø¬Ø§Ø­")
            
            st.divider()
            
            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„Ù
            st.markdown("### ğŸ“‹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                ui.metric_card("Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†", f"{len(hr_df):,}", "", "ğŸ‘¥")
            with col2:
                ui.metric_card("Ø§Ù„Ø­Ù‚ÙˆÙ„", str(len(hr_df.columns)), "", "ğŸ“‹")
            with col3:
                mem = hr_df.memory_usage(deep=True).sum() / 1024**2
                ui.metric_card("Ø§Ù„Ø­Ø¬Ù…", f"{mem:.2f} MB", "", "ğŸ’¾")
            with col4:
                null_pct = (hr_df.isnull().sum().sum() / (len(hr_df) * len(hr_df.columns)) * 100)
                ui.metric_card("Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ©", f"{null_pct:.1f}%", "", "âš ï¸")
            
            st.divider()
            
            # Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            with st.expander("ğŸ‘€ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†", expanded=False):
                ui.data_table_enhanced(hr_df.head(20), max_height=400)
            
            st.divider()
            
            # ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¨Ø´Ø±ÙŠØ©
            st.markdown("### ğŸ¯ Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
            
            hr_analyzer = HRAnalyzer(hr_df)
            columns = hr_df.columns.tolist()
            
            # Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª
            hr_tabs = ui.tabs_enhanced(
                ["ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±ÙˆØ§ØªØ¨", "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¶ÙˆØ±", "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…", "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡", "Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¯ÙŠÙ…ÙˆØºØ±Ø§ÙÙŠ", "ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…"],
                ["ğŸ’°", "ğŸ“…", "ğŸ¢", "â­", "ğŸ‘¤", "ğŸ“Š"]
            )
            
            # ========== ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±ÙˆØ§ØªØ¨ ==========
            with hr_tabs[0]:
                st.markdown("#### ğŸ’° ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±ÙˆØ§ØªØ¨")
                
                col1, col2 = st.columns(2)
                with col1:
                    salary_col = st.selectbox(
                        "Ø§Ø®ØªØ± Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø±Ø§ØªØ¨:",
                        options=columns,
                        key="salary_col"
                    )
                with col2:
                    st.markdown("<br>", unsafe_allow_html=True)
                    analyze_salary_btn = st.button("ğŸš€ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ù„ÙŠÙ„", key="hr_salary", use_container_width=True)
                
                if analyze_salary_btn:
                    with st.spinner("ğŸ“Š Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±ÙˆØ§ØªØ¨..."):
                        results = hr_analyzer.analyze_salaries(salary_col)
                        
                        if "error" not in results:
                            st.success("âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±ÙˆØ§ØªØ¨ Ø¨Ù†Ø¬Ø§Ø­")
                            
                            st.divider()
                            
                            # Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ©
                            st.markdown("##### ğŸ“ˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©")
                            col1, col2, col3, col4 = st.columns(4)
                            
                            with col1:
                                ui.metric_card("Ø§Ù„Ù…ØªÙˆØ³Ø·", f"{results['Ø§Ù„Ù…ØªÙˆØ³Ø·']:,.0f}", "Ø±ÙŠØ§Ù„", "ğŸ’µ")
                            with col2:
                                ui.metric_card("Ø§Ù„ÙˆØ³ÙŠØ·", f"{results['Ø§Ù„ÙˆØ³ÙŠØ·']:,.0f}", "Ø±ÙŠØ§Ù„", "ğŸ“Š")
                            with col3:
                                ui.metric_card("Ø£Ø¹Ù„Ù‰ Ø±Ø§ØªØ¨", f"{results['Ø£Ø¹Ù„Ù‰ Ø±Ø§ØªØ¨']:,.0f}", "Ø±ÙŠØ§Ù„", "ğŸ“ˆ")
                            with col4:
                                ui.metric_card("Ø£Ù‚Ù„ Ø±Ø§ØªØ¨", f"{results['Ø£Ù‚Ù„ Ø±Ø§ØªØ¨']:,.0f}", "Ø±ÙŠØ§Ù„", "ğŸ“‰")
                            
                            st.divider()
                            
                            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.markdown("##### ğŸ“Š ØªÙØ§ØµÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠØ©")
                                st.metric("Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ", f"{results.get('Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ', 0):,.0f}")
                                st.metric("Ø§Ù„Ù…Ø¯Ù‰", f"{results.get('Ø§Ù„Ù…Ø¯Ù‰', results['Ø£Ø¹Ù„Ù‰ Ø±Ø§ØªØ¨'] - results['Ø£Ù‚Ù„ Ø±Ø§ØªØ¨']):,.0f}")
                            
                            with col2:
                                st.markdown("##### ğŸ“ˆ Ø§Ù„Ø±Ø¨Ø¹ÙŠØ§Øª")
                                if salary_col in hr_df.select_dtypes(include=[np.number]).columns:
                                    q1 = hr_df[salary_col].quantile(0.25)
                                    q3 = hr_df[salary_col].quantile(0.75)
                                    st.metric("Ø§Ù„Ø±Ø¨Ø¹ Ø§Ù„Ø£ÙˆÙ„ (25%)", f"{q1:,.0f}")
                                    st.metric("Ø§Ù„Ø±Ø¨Ø¹ Ø§Ù„Ø«Ø§Ù„Ø« (75%)", f"{q3:,.0f}")
                            
                            st.divider()

                            # Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ© (Ù…Ø«Ù„ ØµÙØ­Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª)
                            # 1) Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø±ÙˆØ§ØªØ¨ Ø§Ù„Ø´Ø§Ø°Ø© Ø¥Ù† ÙˆØ¬Ø¯ØªØŒ ÙˆØ¥Ù„Ø§ Ø¹Ø±Ø¶ Ø£Ø¹Ù„Ù‰/Ø£Ù‚Ù„ 20 Ø±Ø§ØªØ¨
                            st.markdown("##### ğŸ“‹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©")
                            salary_series = pd.to_numeric(hr_df[salary_col], errors='coerce')
                            salary_series_no_na = salary_series.dropna()

                            # ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ° Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… IQR
                            if len(salary_series_no_na) > 0:
                                Q1 = salary_series_no_na.quantile(0.25)
                                Q3 = salary_series_no_na.quantile(0.75)
                                IQR = Q3 - Q1
                                outlier_mask = (salary_series < (Q1 - 1.5 * IQR)) | (salary_series > (Q3 + 1.5 * IQR))
                                outliers_df = hr_df.loc[outlier_mask.fillna(False), [salary_col]].copy()
                                outliers_df = outliers_df.sort_values(by=salary_col, ascending=False)
                            else:
                                outliers_df = pd.DataFrame(columns=[salary_col])

                            if len(outliers_df) > 0:
                                ui.data_table_enhanced(outliers_df.head(200), "ğŸ“Œ Ø§Ù„Ø±ÙˆØ§ØªØ¨ Ø§Ù„Ø´Ø§Ø°Ø© (Ø­ØªÙ‰ 200 ØµÙ)")
                            else:
                                top_bottom_col1, top_bottom_col2 = st.columns(2)
                                with top_bottom_col1:
                                    top_df = hr_df[[salary_col]].sort_values(by=salary_col, ascending=False).head(20)
                                    ui.data_table_enhanced(top_df, "Ø£Ø¹Ù„Ù‰ 20 Ø±Ø§ØªØ¨")
                                with top_bottom_col2:
                                    low_df = hr_df[[salary_col]].sort_values(by=salary_col, ascending=True).head(20)
                                    ui.data_table_enhanced(low_df, "Ø£Ù‚Ù„ 20 Ø±Ø§ØªØ¨")
                            
                            # Ø²Ø± ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                            export_buffer = io.BytesIO()
                            with pd.ExcelWriter(export_buffer, engine='openpyxl') as writer:
                                if len(outliers_df) > 0:
                                    outliers_df.to_excel(writer, sheet_name='Outliers', index=False)
                                else:
                                    top_df.to_excel(writer, sheet_name='Top20', index=False)
                                    low_df.to_excel(writer, sheet_name='Bottom20', index=False)
                            st.download_button(
                                label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Excel)",
                                data=export_buffer.getvalue(),
                                file_name=f"salary_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                use_container_width=True
                            )

                            st.divider()
                            
                            # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§ØªØ¨
                            st.markdown("##### ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§ØªØ¨")
                            if salary_col in hr_df.select_dtypes(include=[np.number]).columns:
                                fig = px.histogram(
                                    hr_df,
                                    x=salary_col,
                                    nbins=30,
                                    title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§ØªØ¨",
                                    labels={salary_col: "Ø§Ù„Ø±Ø§ØªØ¨"},
                                    color_discrete_sequence=['#667eea']
                                )
                                fig.update_layout(
                                    xaxis_title="Ø§Ù„Ø±Ø§ØªØ¨ (Ø±ÙŠØ§Ù„)",
                                    yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†",
                                    showlegend=False
                                )
                                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø±Ø³Ù… Ù…Ø¨Ø§Ø´Ø±Ø© Ù„ØªØ¬Ù†Ø¨ Ø¸Ù‡ÙˆØ± HTML ÙƒÙ†Øµ
                                st.plotly_chart(fig, use_container_width=True)
                                st.caption("ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§ØªØ¨ Ø¨ÙŠÙ† Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†")
                        else:
                            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {results['error']}")
            
            # ========== ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¶ÙˆØ± ==========
            with hr_tabs[1]:
                st.markdown("#### ğŸ“… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¶ÙˆØ± ÙˆØ§Ù„ØºÙŠØ§Ø¨")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    attendance_col = st.selectbox(
                        "Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø­Ø¶ÙˆØ±:",
                        options=columns,
                        key="attendance_col"
                    )
                with col2:
                    absence_col = st.selectbox(
                        "Ø¹Ù…ÙˆØ¯ Ø§Ù„ØºÙŠØ§Ø¨:",
                        options=columns,
                        key="absence_col"
                    )
                with col3:
                    threshold = st.number_input(
                        "Ø¹ØªØ¨Ø© Ø§Ù„Ø­Ø¶ÙˆØ± Ø§Ù„Ø¶Ø¹ÙŠÙ",
                        min_value=0,
                        max_value=31,
                        value=20,
                        step=1,
                        key="att_threshold"
                    )
                    st.markdown("<br>", unsafe_allow_html=True)
                    analyze_attendance_btn = st.button("ğŸš€ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ù„ÙŠÙ„", key="hr_attendance", use_container_width=True)
                
                if analyze_attendance_btn:
                    with st.spinner("ğŸ“Š Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¶ÙˆØ±..."):
                        results = hr_analyzer.analyze_attendance(attendance_col, absence_column=absence_col, threshold=int(threshold))
                        
                        if "error" not in results:
                            st.success("âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¶ÙˆØ± Ø¨Ù†Ø¬Ø§Ø­")
                            
                            st.divider()
                            
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                ui.metric_card("Ù†Ø³Ø¨Ø© Ø§Ù„Ø­Ø¶ÙˆØ±", f"{results.get('Ù†Ø³Ø¨Ø© Ø§Ù„Ø­Ø¶ÙˆØ±', 0):.1f}%", "", "âœ…")
                            with col2:
                                ui.metric_card("Ù†Ø³Ø¨Ø© Ø§Ù„ØºÙŠØ§Ø¨", f"{results.get('Ù†Ø³Ø¨Ø© Ø§Ù„ØºÙŠØ§Ø¨', 0):.1f}%", "", "âŒ")
                            with col3:
                                ui.metric_card("Ù…ØªÙˆØ³Ø· Ø§Ù„Ø­Ø¶ÙˆØ±", f"{results.get('Ù…ØªÙˆØ³Ø· Ø§Ù„Ø­Ø¶ÙˆØ±', 0):.1f}", "ÙŠÙˆÙ…", "ğŸ“…")
                            with col4:
                                ui.metric_card("Ù…ØªÙˆØ³Ø· Ø§Ù„ØºÙŠØ§Ø¨", f"{results.get('Ù…ØªÙˆØ³Ø· Ø§Ù„ØºÙŠØ§Ø¨', 0):.1f}", "ÙŠÙˆÙ…", "âš ï¸")

                            st.divider()

                            # Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø«Ù„ ØµÙØ­Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª
                            st.markdown("##### ğŸ“‹ Ø§Ù„Ù…ÙˆØ¸ÙÙˆÙ† Ø°ÙˆÙˆ Ø§Ù„Ø­Ø¶ÙˆØ± Ø§Ù„Ù…Ù†Ø®ÙØ¶")
                            att_numeric = pd.to_numeric(hr_df[attendance_col], errors='coerce')
                            low_att_df = hr_df.loc[att_numeric < int(threshold), [attendance_col] + ([absence_col] if absence_col else [])]
                            ui.data_table_enhanced(low_att_df, "Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø­Ø¶ÙˆØ± Ø§Ù„Ù…Ù†Ø®ÙØ¶")

                            # Ø±Ø³Ù… Ø§Ù„ØªÙˆØ²ÙŠØ¹
                            st.divider()
                            fig = px.histogram(
                                att_numeric.dropna(),
                                nbins=31,
                                title='ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø­Ø¶ÙˆØ± Ø§Ù„Ø´Ù‡Ø±ÙŠ'
                            )
                            st.plotly_chart(fig, use_container_width=True)

                            # ØªÙ†Ø²ÙŠÙ„
                            export_buffer2 = io.BytesIO()
                            with pd.ExcelWriter(export_buffer2, engine='openpyxl') as writer:
                                low_att_df.to_excel(writer, sheet_name='LowAttendance', index=False)
                            st.download_button(
                                label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Excel)",
                                data=export_buffer2.getvalue(),
                                file_name=f"attendance_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                use_container_width=True
                            )
                        else:
                            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {results['error']}")
            
            # ========== ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… ==========
            with hr_tabs[2]:
                st.markdown("#### ğŸ¢ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…")
                
                col1, col2 = st.columns(2)
                with col1:
                    department_col = st.selectbox(
                        "Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù‚Ø³Ù…:",
                        options=columns,
                        key="dept_col"
                    )
                with col2:
                    st.markdown("<br>", unsafe_allow_html=True)
                    analyze_dept_btn = st.button("ğŸš€ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ù„ÙŠÙ„", key="hr_dept", use_container_width=True)
                
                if analyze_dept_btn:
                    with st.spinner("ğŸ“Š Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…..."):
                        results = hr_analyzer.analyze_departments(department_col)
                        
                        if "error" not in results:
                            st.success("âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø¨Ù†Ø¬Ø§Ø­")
                            
                            st.divider()
                            
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                ui.metric_card("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…", str(results.get('Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…', 0)), "", "ğŸ¢")
                            with col2:
                                ui.metric_card("Ø£ÙƒØ¨Ø± Ù‚Ø³Ù…", results.get('Ø£ÙƒØ¨Ø± Ù‚Ø³Ù…', 'N/A'), "", "ğŸ“ˆ")
                            with col3:
                                ui.metric_card("Ø£ØµØºØ± Ù‚Ø³Ù…", results.get('Ø£ØµØºØ± Ù‚Ø³Ù…', 'N/A'), "", "ğŸ“‰")
                            
                            st.divider()
                            
                            # Ø¬Ø¯ÙˆÙ„ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†
                            if 'ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†' in results and results['ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†'] is not None:
                                st.markdown("##### ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ† Ø­Ø³Ø¨ Ø§Ù„Ù‚Ø³Ù…")
                                dept_df = pd.DataFrame(results['ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†'].items(), columns=['Ø§Ù„Ù‚Ø³Ù…', 'Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†'])
                                dept_df = dept_df.sort_values('Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†', ascending=False)
                                ui.data_table_enhanced(dept_df, "ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†")
                                
                                st.divider()
                                
                                # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ø¯Ø§Ø¦Ø±ÙŠ
                                fig = px.pie(
                                    dept_df,
                                    values='Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†',
                                    names='Ø§Ù„Ù‚Ø³Ù…',
                                    title='ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ† Ø­Ø³Ø¨ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…'
                                )
                                ui.chart_card(fig, description="Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ© Ù„ÙƒÙ„ Ù‚Ø³Ù…")
                        else:
                            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {results['error']}")
            
            # ========== ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ ==========
            with hr_tabs[3]:
                st.markdown("#### â­ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡")
                
                col1, col2 = st.columns(2)
                with col1:
                    performance_col = st.selectbox(
                        "Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£Ø¯Ø§Ø¡/Ø§Ù„ØªÙ‚ÙŠÙŠÙ…:",
                        options=columns,
                        key="perf_col"
                    )
                with col2:
                    st.markdown("<br>", unsafe_allow_html=True)
                    analyze_perf_btn = st.button("ğŸš€ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ù„ÙŠÙ„", key="hr_perf", use_container_width=True)
                
                if analyze_perf_btn:
                    with st.spinner("ğŸ“Š Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡..."):
                        results = hr_analyzer.analyze_performance(performance_col)
                        
                        if "error" not in results:
                            st.success("âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¨Ù†Ø¬Ø§Ø­")
                            
                            st.divider()
                            
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                ui.metric_card("Ø§Ù„Ù…ØªÙˆØ³Ø·", f"{results.get('Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø¯Ø§Ø¡', 0):.2f}", "", "ğŸ“Š")
                            with col2:
                                ui.metric_card("Ø£Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡", f"{results.get('Ø£Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡', 0):.2f}", "", "â­")
                            with col3:
                                ui.metric_card("Ø£Ù‚Ù„ Ø£Ø¯Ø§Ø¡", f"{results.get('Ø£Ù‚Ù„ Ø£Ø¯Ø§Ø¡', 0):.2f}", "", "ğŸ“‰")
                            with col4:
                                ui.metric_card("Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ù…ØªØ§Ø²", f"{results.get('Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ù…ØªØ§Ø²', 0):.1f}%", "", "ğŸ†")

                            st.divider()

                            # ØªÙˆØ²ÙŠØ¹ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
                            dist_df = pd.DataFrame({
                                'Ø§Ù„ÙØ¦Ø©': ['Ù…Ù…ØªØ§Ø² (90+)', 'Ø¬ÙŠØ¯ (70-89)', 'Ù…ØªÙˆØ³Ø· (50-69)', 'Ø¶Ø¹ÙŠÙ (<50)'],
                                'Ø§Ù„Ø¹Ø¯Ø¯': [
                                    results.get('Ù…Ù…ØªØ§Ø² (90+)', 0),
                                    results.get('Ø¬ÙŠØ¯ (70-89)', 0),
                                    results.get('Ù…ØªÙˆØ³Ø· (50-69)', 0),
                                    results.get('Ø¶Ø¹ÙŠÙ (<50)', 0)
                                ]
                            })
                            fig = px.bar(dist_df, x='Ø§Ù„ÙØ¦Ø©', y='Ø§Ù„Ø¹Ø¯Ø¯', title='ØªÙˆØ²ÙŠØ¹ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡')
                            st.plotly_chart(fig, use_container_width=True)

                            # Ø§Ù„Ù…ÙˆØ¸ÙÙˆÙ† Ø§Ù„Ù…ØªÙ…ÙŠØ²ÙˆÙ†
                            hp_df = hr_analyzer.find_high_performers(performance_col, threshold=85)
                            if not hp_df.empty and 'error' not in hp_df.columns:
                                ui.data_table_enhanced(hp_df.head(200), "ğŸ“‹ Ø§Ù„Ù…ÙˆØ¸ÙÙˆÙ† Ø§Ù„Ù…ØªÙ…ÙŠØ²ÙˆÙ† (Ø­ØªÙ‰ 200 ØµÙ)")
                                export_buffer3 = io.BytesIO()
                                with pd.ExcelWriter(export_buffer3, engine='openpyxl') as writer:
                                    hp_df.to_excel(writer, sheet_name='HighPerformers', index=False)
                                st.download_button(
                                    label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ØªÙ…ÙŠØ²ÙŠÙ† (Excel)",
                                    data=export_buffer3.getvalue(),
                                    file_name=f"high_performers_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                    use_container_width=True
                                )
                        else:
                            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {results['error']}")
            
            # ========== Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¯ÙŠÙ…ÙˆØºØ±Ø§ÙÙŠ ==========
            with hr_tabs[4]:
                st.markdown("#### ğŸ‘¤ Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¯ÙŠÙ…ÙˆØºØ±Ø§ÙÙŠ")
                
                col1, col2 = st.columns(2)
                with col1:
                    gender_col = st.selectbox(
                        "Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¬Ù†Ø³:",
                        options=columns,
                        key="gender_col"
                    )
                with col2:
                    age_col = st.selectbox(
                        "Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¹Ù…Ø±:",
                        options=columns,
                        key="age_col"
                    )
                
                if st.button("ğŸš€ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ù„ÙŠÙ„", key="hr_demo", use_container_width=True):
                    with st.spinner("ğŸ“Š Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯ÙŠÙ…ÙˆØºØ±Ø§ÙÙŠ..."):
                        results = hr_analyzer.analyze_demographics(gender_col, age_col)
                        
                        if "error" not in results:
                            st.success("âœ… ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯ÙŠÙ…ÙˆØºØ±Ø§ÙÙŠ Ø¨Ù†Ø¬Ø§Ø­")
                            
                            st.divider()
                            
                            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ù†Ø³
                            if 'ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬Ù†Ø³' in results:
                                st.markdown("##### ğŸ‘¥ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬Ù†Ø³")
                                gender_df = pd.DataFrame(results['ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬Ù†Ø³'].items(), columns=['Ø§Ù„Ø¬Ù†Ø³', 'Ø§Ù„Ø¹Ø¯Ø¯'])
                                
                                col1, col2 = st.columns(2)
                                with col1:
                                    ui.data_table_enhanced(gender_df, "Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ù†Ø³")
                                with col2:
                                    fig = px.pie(gender_df, values='Ø§Ù„Ø¹Ø¯Ø¯', names='Ø§Ù„Ø¬Ù†Ø³', title='ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬Ù†Ø³')
                                    st.plotly_chart(fig, use_container_width=True)
                            
                            st.divider()
                            
                            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ù…Ø±
                            if 'Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¹Ù…Ø±' in results:
                                st.markdown("##### ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ù…Ø±")
                                col1, col2, col3, col4 = st.columns(4)
                                with col1:
                                    ui.metric_card("Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¹Ù…Ø±", f"{results['Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¹Ù…Ø±']:.1f}", "Ø³Ù†Ø©", "ğŸ“…")
                                with col2:
                                    ui.metric_card("Ø£ÙƒØ¨Ø± Ø¹Ù…Ø±", str(results.get('Ø£ÙƒØ¨Ø± Ø¹Ù…Ø±', 'N/A')), "Ø³Ù†Ø©", "ğŸ‘´")
                                with col3:
                                    ui.metric_card("Ø£ØµØºØ± Ø¹Ù…Ø±", str(results.get('Ø£ØµØºØ± Ø¹Ù…Ø±', 'N/A')), "Ø³Ù†Ø©", "ğŸ‘¶")
                                with col4:
                                    ui.metric_card("Ø§Ù„ÙˆØ³ÙŠØ·", f"{results.get('ÙˆØ³ÙŠØ· Ø§Ù„Ø¹Ù…Ø±', 0):.1f}", "Ø³Ù†Ø©", "ğŸ“Š")

                                # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø§Ø±
                                age_numeric = pd.to_numeric(hr_df[age_col], errors='coerce') if age_col in hr_df.columns else pd.Series([], dtype=float)
                                if age_numeric.dropna().shape[0] > 0:
                                    st.divider()
                                    fig_age = px.histogram(age_numeric.dropna(), nbins=30, title='ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø§Ø±')
                                    st.plotly_chart(fig_age, use_container_width=True)
                        else:
                            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {results['error']}")
            
            # ========== ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… ==========
            with hr_tabs[5]:
                st.markdown("#### ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…")
                
                ui.info_box(
                    "ØªØ­Ù„ÙŠÙ„Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©",
                    "Ø§Ø®ØªØ± Ø¹Ø¯Ø© Ø­Ù‚ÙˆÙ„ Ù„Ø¥Ø¬Ø±Ø§Ø¡ ØªØ­Ù„ÙŠÙ„Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø© ÙˆÙ…Ù‚Ø§Ø±Ù†Ø§Øª Ø´Ø§Ù…Ù„Ø©",
                    "info"
                )
                
                st.markdown("##### ğŸ“‹ Ø§Ø®ØªØ± Ø§Ù„Ø­Ù‚ÙˆÙ„ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
                selected_cols = st.multiselect(
                    "Ø§Ø®ØªØ± Ø­Ù‚Ù„ Ø£Ùˆ Ø£ÙƒØ«Ø±:",
                    options=columns,
                    key="advanced_cols"
                )
                
                if st.button("ğŸš€ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…", key="hr_advanced", use_container_width=True):
                    if selected_cols:
                        with st.spinner("ğŸ“Š Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…..."):
                            st.success(f"âœ… ØªÙ… Ø§Ø®ØªÙŠØ§Ø± {len(selected_cols)} Ø­Ù‚Ù„ Ù„Ù„ØªØ­Ù„ÙŠÙ„")
                            
                            st.divider()
                            
                            # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù„ÙƒÙ„ Ø­Ù‚Ù„
                            for col in selected_cols:
                                st.markdown(f"##### ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: {col}")
                                
                                if hr_df[col].dtype in ['int64', 'float64']:
                                    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù„Ù„Ø£Ø±Ù‚Ø§Ù…
                                    col1, col2, col3, col4 = st.columns(4)
                                    with col1:
                                        st.metric("Ø§Ù„Ù…ØªÙˆØ³Ø·", f"{hr_df[col].mean():.2f}")
                                    with col2:
                                        st.metric("Ø§Ù„ÙˆØ³ÙŠØ·", f"{hr_df[col].median():.2f}")
                                    with col3:
                                        st.metric("Ø§Ù„Ø£Ø¹Ù„Ù‰", f"{hr_df[col].max():.2f}")
                                    with col4:
                                        st.metric("Ø§Ù„Ø£Ù‚Ù„", f"{hr_df[col].min():.2f}")
                                else:
                                    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù„Ù„Ù†ØµÙˆØµ
                                    col1, col2, col3 = st.columns(3)
                                    with col1:
                                        st.metric("Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø©", f"{hr_df[col].nunique()}")
                                    with col2:
                                        st.metric("Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹", str(hr_df[col].mode()[0]) if len(hr_df[col].mode()) > 0 else "N/A")
                                    with col3:
                                        st.metric("Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ©", f"{hr_df[col].isnull().sum()}")
                                
                                st.divider()
                    else:
                        st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø­Ù‚Ù„ ÙˆØ§Ø­Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„")
        
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {str(e)}")
            st.info("ğŸ’¡ ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù„Ù ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ØµØ­ÙŠØ­Ø©")
    
    else:
        ui.empty_state(
            icon="ğŸ‘¥",
            title="Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†",
            description="Ø§Ø±ÙØ¹ Ù…Ù„Ù Excel Ø£Ùˆ CSV Ù„Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¨Ø´Ø±ÙŠØ©"
        )

# ==================== ÙØ­ÙˆØµØ§Øª Ù…Ø®ØµØµØ© ====================
elif current_page == "ğŸ”§ ÙØ­ÙˆØµØ§Øª Ù…Ø®ØµØµØ©":
    
    ui.gradient_header("ÙØ­ÙˆØµØ§Øª Ù…Ø®ØµØµØ©", "Ø£Ù†Ø´Ø¦ ÙØ­ÙˆØµØ§ØªÙƒ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø³Ù‡ÙˆÙ„Ø©", "ğŸ”§")
    
    generator = SmartTestGenerator()
    
    custom_tabs = ui.tabs_enhanced(
        ["Ø¥Ø¶Ø§ÙØ© ÙØ­Øµ", "ÙØ­ÙˆØµØ§ØªÙŠ", "ØªØ´ØºÙŠÙ„"],
        ["â•", "ğŸ“‹", "â–¶ï¸"]
    )
    
    with custom_tabs[0]:
        ui.info_box(
            "ÙƒÙŠÙÙŠØ© Ø§Ù„Ø¥Ø¶Ø§ÙØ©",
            "Ø§Ø®ØªØ± Ù‚Ø§Ù„Ø¨Ø§Ù‹ Ø¬Ø§Ù‡Ø²Ø§Ù‹ØŒ Ø£Ø¯Ø®Ù„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§ØªØŒ ÙˆØ§Ø­ÙØ¸ Ø§Ù„ÙØ­Øµ!",
            "info"
        )
        
        st.markdown("### â• ÙØ­Øµ Ø¬Ø¯ÙŠØ¯")
        
        templates = generator.get_available_templates()
        template = st.selectbox("Ù†ÙˆØ¹ Ø§Ù„ÙØ­Øµ:", templates)
        
        test_name = st.text_input("Ø§Ø³Ù… Ø§Ù„ÙØ­Øµ:")
        test_desc = st.text_area("Ø§Ù„ÙˆØµÙ:")
        column_name = st.text_input("Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯:")
        
        params = {}
        if template == "Ù…Ù‚Ø§Ø±Ù†Ø©":
            col1, col2 = st.columns(2)
            params['operator'] = col1.selectbox("Ø§Ù„Ù…Ø¹Ø§Ù…Ù„:", [">", "<", "=="])
            params['value'] = col2.number_input("Ø§Ù„Ù‚ÙŠÙ…Ø©:", value=0.0)
        
        if st.button("ğŸ’¾ Ø­ÙØ¸", use_container_width=True):
            if test_name and test_desc and column_name:
                result = generator.create_test_from_template(
                    test_name, test_desc, template, column_name, **params
                )
                if result.get('success'):
                    st.success(f"âœ… ØªÙ… Ø§Ù„Ø­ÙØ¸! ID: {result['test_id']}")
                    st.balloons()

# ==================== Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙØ­ÙˆØµØ§Øª ====================
elif current_page == "âœ… Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙØ­ÙˆØµØ§Øª":
    
    ui.gradient_header("Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙØ­ÙˆØµØ§Øª", "Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙØ­ÙˆØµØ§Øª Ù†Ø¬Ø­Øª 100%", "âœ…")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        ui.metric_card("Ø§Ù„Ù†Ø¬Ø§Ø­", "100%", "6/6", "ğŸ¯")
    with col2:
        ui.metric_card("Ø§Ù„Ø£Ø®Ø·Ø§Ø¡", "0", "ØªÙ… Ø§Ù„Ø¥ØµÙ„Ø§Ø­", "ğŸ”§")
    with col3:
        ui.metric_card("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "28,636", "ØµÙ", "ğŸ“Š")
    with col4:
        ui.metric_card("Ø§Ù„ØªÙ‚ÙŠÙŠÙ…", "5/5", "Ù…Ù…ØªØ§Ø²", "â­")

# ==================== Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ… ====================
elif current_page == "ğŸ“Š Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…":
    
    ui.gradient_header("Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…", "Ù†Ø¸Ø±Ø© Ø´Ø§Ù…Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø¸Ø§Ù…", "ğŸ“Š")
    
    if len(st.session_state.analysis_history) > 0:
        st.markdown("### ğŸ“œ Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª")
        for item in st.session_state.analysis_history[-5:]:
            st.markdown(f"- **{item['type']}** - {item['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
    else:
        ui.empty_state(
            icon="ğŸ“Š",
            title="Ù„Ø§ ØªÙˆØ¬Ø¯ ØªØ­Ù„ÙŠÙ„Ø§Øª",
            description="Ø§Ø¨Ø¯Ø£ Ø¨Ø¥Ø¬Ø±Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø³Ø¬Ù„"
        )

# ==================== Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ====================
elif current_page == "ğŸ“š Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…":
    
    ui.gradient_header("Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…", "ÙƒÙ„ Ù…Ø§ ØªØ­ØªØ§Ø¬ Ù…Ø¹Ø±ÙØªÙ‡", "ğŸ“š")
    
    guide_tabs = ui.tabs_enhanced(
        ["Ø§Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø³Ø±ÙŠØ¹", "Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª", "Ø§Ù„Ø£Ø³Ø¦Ù„Ø©"],
        ["ğŸš€", "ğŸ“Š", "â“"]
    )
    
    with guide_tabs[0]:
        ui.timeline_card(
            "Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø¨Ø¯Ø¡",
            [
                {"title": "Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù", "description": "Ø§Ø°Ù‡Ø¨ Ù„Ù‚Ø³Ù… 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª'"},
                {"title": "Ø§Ø®ØªØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„", "description": "Ø­Ø¯Ø¯ Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨"},
                {"title": "Ø¶Ø¨Ø· Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª", "description": "Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª"},
                {"title": "Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", "description": "Ø´Ø§Ù‡Ø¯ ÙˆØ­Ù…Ù‘Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ±"}
            ]
        )

# ==================== Ø§Ù„ØªØ°ÙŠÙŠÙ„ ====================
ui.footer(
    app_name="Data Analest",
    version="2.0.0",
    developer="GitHub Copilot",
    year=2025
)
